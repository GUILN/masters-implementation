{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55adac5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 10:34:11,866 - INFO - Sentry DSN set to: https://f4f21cc936b3ba9f5dbc1464b7a40ea4@o4504168838070272.ingest.us.sentry.io/4506464560414720\n",
      "2025-10-22 10:34:11,867 - INFO - Sentry initialized with environment: development\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading config...\n",
      "Loading secrets...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from typing import Dict\n",
    "import sys\n",
    "sys.path.append(str(Path(os.getcwd()).parent))\n",
    "\n",
    "from settings.global_settings import GlobalSettings\n",
    "\n",
    "config = GlobalSettings.get_config(\n",
    "    config_file = \"../config.ini\",\n",
    "    secrets_file = \"../secrets.ini\"\n",
    ")\n",
    "from dataset.video_loader import VideoDataLoader\n",
    "from dataset.video_dataset import VideoDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb59f55b",
   "metadata": {},
   "source": [
    "## Loading VideoDataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "202925f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DIR = \"train\"\n",
    "TEST_DIR = \"test\"\n",
    "\n",
    "\n",
    "train_video_data_loader = VideoDataLoader(\n",
    "    path=os.path.join(config.model_settings.video_data_dir, TRAIN_DIR)\n",
    ")\n",
    "test_video_data_loader = VideoDataLoader(\n",
    "    path=os.path.join(config.model_settings.video_data_dir, TEST_DIR)\n",
    ")\n",
    "\n",
    "train_video_dataset = VideoDataset(\n",
    "    video_data_loader=train_video_data_loader,\n",
    ")\n",
    "test_video_dataset = VideoDataset(\n",
    "    video_data_loader=test_video_data_loader,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c08026",
   "metadata": {},
   "source": [
    "**Testing video_dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69e7df2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 10:34:14,179 - INFO - [VideoDataLoader] Loding action videos for action: a01\n",
      "2025-10-22 10:34:14,425 - INFO - [VideoDataLoader] Loding action videos for action: a02\n",
      "2025-10-22 10:34:14,741 - INFO - [VideoDataLoader] Loding action videos for action: a03\n",
      "2025-10-22 10:34:15,051 - INFO - [VideoDataLoader] Loding action videos for action: a04\n",
      "2025-10-22 10:34:15,530 - INFO - [VideoDataLoader] Loding action videos for action: a05\n",
      "2025-10-22 10:34:15,749 - INFO - [VideoDataLoader] Loding action videos for action: a06\n",
      "2025-10-22 10:34:15,971 - INFO - [VideoDataLoader] Loding action videos for action: a08\n",
      "2025-10-22 10:34:16,568 - INFO - [VideoDataLoader] Loding action videos for action: a09\n",
      "2025-10-22 10:34:17,111 - INFO - [VideoDataLoader] Loding action videos for action: a11\n",
      "2025-10-22 10:34:17,332 - INFO - [VideoDataLoader] Loding action videos for action: a12\n",
      "2025-10-22 10:34:17,564 - INFO - [VideoDataLoader] Loding action videos for action: a01\n",
      "2025-10-22 10:34:17,635 - INFO - [VideoDataLoader] Loding action videos for action: a02\n",
      "2025-10-22 10:34:17,967 - INFO - [VideoDataLoader] Loding action videos for action: a03\n",
      "2025-10-22 10:34:18,027 - INFO - [VideoDataLoader] Loding action videos for action: a04\n",
      "2025-10-22 10:34:18,093 - INFO - [VideoDataLoader] Loding action videos for action: a05\n",
      "2025-10-22 10:34:18,162 - INFO - [VideoDataLoader] Loding action videos for action: a06\n",
      "2025-10-22 10:34:18,217 - INFO - [VideoDataLoader] Loding action videos for action: a08\n",
      "2025-10-22 10:34:18,352 - INFO - [VideoDataLoader] Loding action videos for action: a09\n",
      "2025-10-22 10:34:18,447 - INFO - [VideoDataLoader] Loding action videos for action: a11\n",
      "2025-10-22 10:34:18,508 - INFO - [VideoDataLoader] Loding action videos for action: a12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1475\n"
     ]
    }
   ],
   "source": [
    "print(len(train_video_dataset) + len(test_video_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf6c80b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Data(x=[6, 5], edge_index=[2, 30]), Data(x=[7, 5], edge_index=[2, 42]), Data(x=[8, 5], edge_index=[2, 56]), Data(x=[7, 5], edge_index=[2, 42]), Data(x=[7, 5], edge_index=[2, 42]), Data(x=[7, 5], edge_index=[2, 42]), Data(x=[7, 5], edge_index=[2, 42]), Data(x=[7, 5], edge_index=[2, 42]), Data(x=[7, 5], edge_index=[2, 42]), Data(x=[7, 5], edge_index=[2, 42]), Data(x=[8, 5], edge_index=[2, 56]), Data(x=[7, 5], edge_index=[2, 42]), Data(x=[6, 5], edge_index=[2, 30])]\n"
     ]
    }
   ],
   "source": [
    "print(train_video_dataset[0].graphs_objects)  # Print the first item in the dataset for verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64402a99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3,\n",
      "         4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6],\n",
      "        [1, 2, 3, 4, 5, 6, 0, 2, 3, 4, 5, 6, 0, 1, 3, 4, 5, 6, 0, 1, 2, 4, 5, 6,\n",
      "         0, 1, 2, 3, 5, 6, 0, 1, 2, 3, 4, 6, 0, 1, 2, 3, 4, 5]])\n"
     ]
    }
   ],
   "source": [
    "print(train_video_dataset[2].graphs_objects[0].edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "295c8784",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3,\n",
      "         4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6],\n",
      "        [1, 2, 3, 4, 5, 6, 0, 2, 3, 4, 5, 6, 0, 1, 3, 4, 5, 6, 0, 1, 2, 4, 5, 6,\n",
      "         0, 1, 2, 3, 5, 6, 0, 1, 2, 3, 4, 6, 0, 1, 2, 3, 4, 5]])\n"
     ]
    }
   ],
   "source": [
    "print(train_video_dataset[2].graphs_objects[0].edge_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5020300",
   "metadata": {},
   "source": [
    "**Test from Dataloader:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "444658f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VideoData(graphs_objects=[Data(x=[4, 5], edge_index=[2, 12]), Data(x=[5, 5], edge_index=[2, 20]), Data(x=[3, 5], edge_index=[2, 6]), Data(x=[4, 5], edge_index=[2, 12]), Data(x=[4, 5], edge_index=[2, 12]), Data(x=[4, 5], edge_index=[2, 12]), Data(x=[4, 5], edge_index=[2, 12]), Data(x=[4, 5], edge_index=[2, 12]), Data(x=[4, 5], edge_index=[2, 12]), Data(x=[4, 5], edge_index=[2, 12]), Data(x=[3, 5], edge_index=[2, 6])], graphs_joints=[Data(x=[17, 3], edge_index=[2, 272]), Data(x=[17, 3], edge_index=[2, 272]), Data(x=[17, 3], edge_index=[2, 272]), Data(x=[17, 3], edge_index=[2, 272]), Data(x=[17, 3], edge_index=[2, 272]), Data(x=[17, 3], edge_index=[2, 272]), Data(x=[17, 3], edge_index=[2, 272]), Data(x=[17, 3], edge_index=[2, 272]), Data(x=[17, 3], edge_index=[2, 272]), Data(x=[17, 3], edge_index=[2, 272]), Data(x=[17, 3], edge_index=[2, 272])], label=tensor(1)), VideoData(graphs_objects=[Data(x=[4, 5], edge_index=[2, 12]), Data(x=[3, 5], edge_index=[2, 6]), Data(x=[2, 5], edge_index=[2, 2]), Data(x=[3, 5], edge_index=[2, 6]), Data(x=[4, 5], edge_index=[2, 12]), Data(x=[3, 5], edge_index=[2, 6]), Data(x=[3, 5], edge_index=[2, 6]), Data(x=[3, 5], edge_index=[2, 6]), Data(x=[3, 5], edge_index=[2, 6]), Data(x=[4, 5], edge_index=[2, 12]), Data(x=[5, 5], edge_index=[2, 20]), Data(x=[4, 5], edge_index=[2, 12]), Data(x=[2, 5], edge_index=[2, 2])], graphs_joints=[Data(x=[17, 3], edge_index=[2, 272]), Data(x=[17, 3], edge_index=[2, 272]), Data(x=[17, 3], edge_index=[2, 272]), Data(x=[17, 3], edge_index=[2, 272]), Data(x=[17, 3], edge_index=[2, 272]), Data(x=[17, 3], edge_index=[2, 272]), Data(x=[17, 3], edge_index=[2, 272]), Data(x=[17, 3], edge_index=[2, 272]), Data(x=[17, 3], edge_index=[2, 272]), Data(x=[17, 3], edge_index=[2, 272]), Data(x=[17, 3], edge_index=[2, 272]), Data(x=[17, 3], edge_index=[2, 272]), Data(x=[17, 3], edge_index=[2, 272])], label=tensor(1))]\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "loader = DataLoader(train_video_dataset, batch_size=2, shuffle=True, collate_fn=lambda x: x)\n",
    "for batch in loader:\n",
    "    print(batch)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8912b4da",
   "metadata": {},
   "source": [
    "**Verifying Labels**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a002419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "{'a01': 0, 'a05': 1, 'a02': 2, 'a03': 3, 'a04': 4, 'a06': 5, 'a08': 6, 'a09': 7, 'a11': 8, 'a12': 9}\n"
     ]
    }
   ],
   "source": [
    "# print(video_dataset[1000].graphs_objects[0].edge_index)\n",
    "for video_data in train_video_dataset:\n",
    "    pass\n",
    "print(len(train_video_dataset.labels_map))\n",
    "print(train_video_dataset.labels_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb4c3df",
   "metadata": {},
   "source": [
    "**Verifying Feature Dimension**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f25fc90d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "print(train_video_dataset[0].graphs_objects[0].x.shape[1])\n",
    "print(train_video_dataset[0].graphs_joints[0].x.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f641a7f3",
   "metadata": {},
   "source": [
    "## Analyzing Video Category Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "00fe37aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_videos_distribution(video_dataset: VideoDataset) -> Dict[str, int]:\n",
    "    videos_distribution = {}\n",
    "    for video_data in video_dataset:\n",
    "        label = video_dataset.get_label_name_from_label_value(video_data.label)\n",
    "        if label not in videos_distribution:\n",
    "            videos_distribution[label] = 0\n",
    "        videos_distribution[label] += 1\n",
    "    return videos_distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b7a71772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Videos Distribution:\n",
      "Total: 1176\n",
      "{'a01': 118, 'a02': 116, 'a03': 112, 'a04': 138, 'a05': 118, 'a06': 119, 'a08': 113, 'a09': 113, 'a11': 116, 'a12': 113}\n",
      "Test Videos Distribution:\n",
      "Total: 299\n",
      "{'a01': 30, 'a02': 30, 'a03': 28, 'a04': 35, 'a05': 30, 'a06': 30, 'a08': 29, 'a09': 29, 'a11': 29, 'a12': 29}\n"
     ]
    }
   ],
   "source": [
    "train_videos_distribution = get_videos_distribution(train_video_dataset)\n",
    "print(\"Train Videos Distribution:\")\n",
    "print(f\"Total: {sum(train_videos_distribution.values())}\")\n",
    "print(train_videos_distribution)\n",
    "test_videos_distribution = get_videos_distribution(test_video_dataset)\n",
    "print(\"Test Videos Distribution:\")\n",
    "print(f\"Total: {sum(test_videos_distribution.values())}\")\n",
    "print(test_videos_distribution)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
