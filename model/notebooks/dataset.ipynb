{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55adac5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-24 22:42:30,113 - INFO - Sentry DSN set to: https://f4f21cc936b3ba9f5dbc1464b7a40ea4@o4504168838070272.ingest.us.sentry.io/4506464560414720\n",
      "2025-10-24 22:42:30,114 - INFO - Sentry initialized with environment: development\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading config...\n",
      "Loading secrets...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from typing import Dict\n",
    "import sys\n",
    "sys.path.append(str(Path(os.getcwd()).parent))\n",
    "\n",
    "from settings.global_settings import GlobalSettings\n",
    "\n",
    "config = GlobalSettings.get_config(\n",
    "    config_file = \"../config.ini\",\n",
    "    secrets_file = \"../secrets.ini\"\n",
    ")\n",
    "from dataset.video_loader import VideoDataLoader\n",
    "from dataset.video_dataset import VideoDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb59f55b",
   "metadata": {},
   "source": [
    "## Loading VideoDataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "202925f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DIR = \"train\"\n",
    "TEST_DIR = \"test\"\n",
    "VALIDATION_DIR = \"validation\"\n",
    "\n",
    "\n",
    "train_video_data_loader = VideoDataLoader(\n",
    "    path=os.path.join(config.model_settings.video_data_dir, TRAIN_DIR)\n",
    ")\n",
    "test_video_data_loader = VideoDataLoader(\n",
    "    path=os.path.join(config.model_settings.video_data_dir, TEST_DIR)\n",
    ")\n",
    "validation_video_data_loader = VideoDataLoader(\n",
    "    path=os.path.join(config.model_settings.video_data_dir, VALIDATION_DIR)\n",
    ")\n",
    "\n",
    "train_video_dataset = VideoDataset(\n",
    "    video_data_loader=train_video_data_loader,\n",
    ")\n",
    "test_video_dataset = VideoDataset(\n",
    "    video_data_loader=test_video_data_loader,\n",
    ")\n",
    "validation_video_dataset = VideoDataset(\n",
    "    video_data_loader=validation_video_data_loader,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c08026",
   "metadata": {},
   "source": [
    "**Testing video_dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69e7df2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-24 22:42:48,090 - INFO - [VideoDataLoader] Loding action videos for action: a01\n",
      "2025-10-24 22:42:48,632 - INFO - [VideoDataLoader] Loding action videos for action: a02\n",
      "2025-10-24 22:42:49,236 - INFO - [VideoDataLoader] Loding action videos for action: a03\n",
      "2025-10-24 22:42:49,672 - INFO - [VideoDataLoader] Loding action videos for action: a04\n",
      "2025-10-24 22:42:50,370 - INFO - [VideoDataLoader] Loding action videos for action: a05\n",
      "2025-10-24 22:42:50,903 - INFO - [VideoDataLoader] Loding action videos for action: a06\n",
      "2025-10-24 22:42:51,320 - INFO - [VideoDataLoader] Loding action videos for action: a08\n",
      "2025-10-24 22:42:52,291 - INFO - [VideoDataLoader] Loding action videos for action: a09\n",
      "2025-10-24 22:42:53,174 - INFO - [VideoDataLoader] Loding action videos for action: a11\n",
      "2025-10-24 22:42:53,505 - INFO - [VideoDataLoader] Loding action videos for action: a12\n",
      "2025-10-24 22:42:53,927 - INFO - [VideoDataLoader] Loding action videos for action: a01\n",
      "2025-10-24 22:42:53,992 - INFO - [VideoDataLoader] Loding action videos for action: a02\n",
      "2025-10-24 22:42:54,083 - INFO - [VideoDataLoader] Loding action videos for action: a03\n",
      "2025-10-24 22:42:54,346 - INFO - [VideoDataLoader] Loding action videos for action: a04\n",
      "2025-10-24 22:42:54,413 - INFO - [VideoDataLoader] Loding action videos for action: a05\n",
      "2025-10-24 22:42:54,534 - INFO - [VideoDataLoader] Loding action videos for action: a06\n",
      "2025-10-24 22:42:54,611 - INFO - [VideoDataLoader] Loding action videos for action: a08\n",
      "2025-10-24 22:42:54,678 - INFO - [VideoDataLoader] Loding action videos for action: a09\n",
      "2025-10-24 22:42:54,781 - INFO - [VideoDataLoader] Loding action videos for action: a11\n",
      "2025-10-24 22:42:54,809 - INFO - [VideoDataLoader] Loding action videos for action: a12\n",
      "2025-10-24 22:42:54,839 - INFO - [VideoDataLoader] Loding action videos for action: a01\n",
      "2025-10-24 22:42:54,874 - INFO - [VideoDataLoader] Loding action videos for action: a02\n",
      "2025-10-24 22:42:54,937 - INFO - [VideoDataLoader] Loding action videos for action: a03\n",
      "2025-10-24 22:42:55,029 - INFO - [VideoDataLoader] Loding action videos for action: a04\n",
      "2025-10-24 22:42:55,063 - INFO - [VideoDataLoader] Loding action videos for action: a05\n",
      "2025-10-24 22:42:55,096 - INFO - [VideoDataLoader] Loding action videos for action: a06\n",
      "2025-10-24 22:42:55,125 - INFO - [VideoDataLoader] Loding action videos for action: a08\n",
      "2025-10-24 22:42:55,258 - INFO - [VideoDataLoader] Loding action videos for action: a09\n",
      "2025-10-24 22:42:55,309 - INFO - [VideoDataLoader] Loding action videos for action: a11\n",
      "2025-10-24 22:42:55,345 - INFO - [VideoDataLoader] Loding action videos for action: a12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1475\n"
     ]
    }
   ],
   "source": [
    "print(len(train_video_dataset) + len(test_video_dataset) + len(validation_video_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6c80b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_video_dataset[0].graphs_objects)  # Print the first item in the dataset for verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64402a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_video_dataset[2].graphs_objects[0].edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295c8784",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_video_dataset[2].graphs_objects[0].edge_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5020300",
   "metadata": {},
   "source": [
    "**Test from Dataloader:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444658f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "loader = DataLoader(train_video_dataset, batch_size=2, shuffle=True, collate_fn=lambda x: x)\n",
    "for batch in loader:\n",
    "    print(batch)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8912b4da",
   "metadata": {},
   "source": [
    "**Verifying Labels**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a002419",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(video_dataset[1000].graphs_objects[0].edge_index)\n",
    "for video_data in train_video_dataset:\n",
    "    pass\n",
    "print(len(train_video_dataset.labels_map))\n",
    "print(train_video_dataset.labels_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb4c3df",
   "metadata": {},
   "source": [
    "**Verifying Feature Dimension**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25fc90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_video_dataset[0].graphs_objects[0].x.shape[1])\n",
    "print(train_video_dataset[0].graphs_joints[0].x.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f641a7f3",
   "metadata": {},
   "source": [
    "## Analyzing Video Category Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00fe37aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_videos_distribution(video_dataset: VideoDataset) -> Dict[str, int]:\n",
    "    videos_distribution = {}\n",
    "    for video_data in video_dataset:\n",
    "        label = video_dataset.get_label_name_from_label_value(video_data.label)\n",
    "        if label not in videos_distribution:\n",
    "            videos_distribution[label] = 0\n",
    "        videos_distribution[label] += 1\n",
    "    return videos_distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a71772",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_videos_distribution = get_videos_distribution(train_video_dataset)\n",
    "print(\"Train Videos Distribution:\")\n",
    "print(f\"Total: {sum(train_videos_distribution.values())}\")\n",
    "print(train_videos_distribution)\n",
    "test_videos_distribution = get_videos_distribution(test_video_dataset)\n",
    "print(\"Test Videos Distribution:\")\n",
    "print(f\"Total: {sum(test_videos_distribution.values())}\")\n",
    "print(test_videos_distribution)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
