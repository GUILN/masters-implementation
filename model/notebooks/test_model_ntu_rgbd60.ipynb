{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1b2d9ef",
   "metadata": {},
   "source": [
    "# Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84a5065f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (DatabaseError('database disk image is malformed')).History will not be written to the database.\n",
      "Loading config...\n",
      "Loading secrets...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-21 22:47:54,754 - INFO - Sentry DSN set to: https://f4f21cc936b3ba9f5dbc1464b7a40ea4@o4504168838070272.ingest.us.sentry.io/4506464560414720\n",
      "2025-12-21 22:47:54,755 - INFO - Sentry initialized with environment: development\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import sys\n",
    "sys.path.append(str(Path(os.getcwd()).parent))\n",
    "\n",
    "from settings.global_settings import GlobalSettings\n",
    "\n",
    "config = GlobalSettings.get_config(\n",
    "    config_file = \"../config.ini\",\n",
    "    secrets_file = \"../secrets.ini\"\n",
    ")\n",
    "from dataset.video_loader import VideoDataLoader\n",
    "from dataset.video_dataset import VideoDataset, default_augmentation_pipeline\n",
    "from model.training_loop import train, EarlyStoppingParams\n",
    "from model.multimodal_har_model import MultiModalHARModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b74259d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "OBSERVATION_RATIO = 20\n",
    "EAR_RATIO = OBSERVATION_RATIO / 100\n",
    "WITH_OBJECT_BRANCH = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6cf9b62",
   "metadata": {},
   "source": [
    "## Initializing Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d691d46",
   "metadata": {},
   "source": [
    "**Creating Dataloaders**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d84473d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-21 22:47:56,775 - INFO - [VideoDataLoader] Loding action videos for action: A001\n",
      "2025-12-21 22:47:57,517 - INFO - [VideoDataLoader] Loding action videos for action: A002\n",
      "2025-12-21 22:47:58,273 - INFO - [VideoDataLoader] Loding action videos for action: A004\n",
      "2025-12-21 22:47:59,059 - INFO - [VideoDataLoader] Loding action videos for action: A006\n",
      "2025-12-21 22:47:59,824 - INFO - [VideoDataLoader] Loding action videos for action: A011\n",
      "2025-12-21 22:48:00,805 - INFO - [VideoDataLoader] Loding action videos for action: A012\n",
      "2025-12-21 22:48:01,767 - INFO - [VideoDataLoader] Loding action videos for action: A013\n",
      "2025-12-21 22:48:02,672 - INFO - [VideoDataLoader] Loding action videos for action: A014\n",
      "2025-12-21 22:48:03,972 - INFO - [VideoDataLoader] Loding action videos for action: A015\n",
      "2025-12-21 22:48:04,935 - INFO - [VideoDataLoader] Loding action videos for action: A020\n",
      "2025-12-21 22:48:05,748 - INFO - [VideoDataLoader] Loding action videos for action: A021\n",
      "2025-12-21 22:48:06,297 - INFO - [VideoDataLoader] Loding action videos for action: A028\n",
      "2025-12-21 22:48:07,139 - INFO - [VideoDataLoader] Loding action videos for action: A029\n",
      "2025-12-21 22:48:08,269 - INFO - [VideoDataLoader] Loding action videos for action: A030\n",
      "2025-12-21 22:48:09,133 - INFO - [VideoDataLoader] Loding action videos for action: A032\n",
      "2025-12-21 22:48:11,818 - INFO - [VideoDataLoader] Loding action videos for action: A001\n",
      "2025-12-21 22:48:11,867 - INFO - [VideoDataLoader] Loding action videos for action: A002\n",
      "2025-12-21 22:48:12,686 - INFO - [VideoDataLoader] Loding action videos for action: A004\n",
      "2025-12-21 22:48:12,741 - INFO - [VideoDataLoader] Loding action videos for action: A006\n",
      "2025-12-21 22:48:12,851 - INFO - [VideoDataLoader] Loding action videos for action: A011\n",
      "2025-12-21 22:48:12,909 - INFO - [VideoDataLoader] Loding action videos for action: A012\n",
      "2025-12-21 22:48:13,029 - INFO - [VideoDataLoader] Loding action videos for action: A013\n",
      "2025-12-21 22:48:13,083 - INFO - [VideoDataLoader] Loding action videos for action: A014\n",
      "2025-12-21 22:48:13,219 - INFO - [VideoDataLoader] Loding action videos for action: A015\n",
      "2025-12-21 22:48:13,354 - INFO - [VideoDataLoader] Loding action videos for action: A020\n",
      "2025-12-21 22:48:13,405 - INFO - [VideoDataLoader] Loding action videos for action: A021\n",
      "2025-12-21 22:48:13,450 - INFO - [VideoDataLoader] Loding action videos for action: A028\n",
      "2025-12-21 22:48:13,571 - INFO - [VideoDataLoader] Loding action videos for action: A029\n",
      "2025-12-21 22:48:13,625 - INFO - [VideoDataLoader] Loding action videos for action: A030\n",
      "2025-12-21 22:48:13,744 - INFO - [VideoDataLoader] Loding action videos for action: A032\n",
      "2025-12-21 22:48:14,077 - INFO - [VideoDataLoader] Loding action videos for action: A001\n",
      "2025-12-21 22:48:14,128 - INFO - [VideoDataLoader] Loding action videos for action: A002\n",
      "2025-12-21 22:48:14,181 - INFO - [VideoDataLoader] Loding action videos for action: A004\n",
      "2025-12-21 22:48:14,294 - INFO - [VideoDataLoader] Loding action videos for action: A006\n",
      "2025-12-21 22:48:14,344 - INFO - [VideoDataLoader] Loding action videos for action: A011\n",
      "2025-12-21 22:48:14,468 - INFO - [VideoDataLoader] Loding action videos for action: A012\n",
      "2025-12-21 22:48:14,527 - INFO - [VideoDataLoader] Loding action videos for action: A013\n",
      "2025-12-21 22:48:14,647 - INFO - [VideoDataLoader] Loding action videos for action: A014\n",
      "2025-12-21 22:48:14,791 - INFO - [VideoDataLoader] Loding action videos for action: A015\n",
      "2025-12-21 22:48:14,861 - INFO - [VideoDataLoader] Loding action videos for action: A020\n",
      "2025-12-21 22:48:14,971 - INFO - [VideoDataLoader] Loding action videos for action: A021\n",
      "2025-12-21 22:48:15,049 - INFO - [VideoDataLoader] Loding action videos for action: A028\n",
      "2025-12-21 22:48:15,122 - INFO - [VideoDataLoader] Loding action videos for action: A029\n",
      "2025-12-21 22:48:15,243 - INFO - [VideoDataLoader] Loding action videos for action: A030\n",
      "2025-12-21 22:48:15,304 - INFO - [VideoDataLoader] Loding action videos for action: A032\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "TRAIN_DIR = os.path.join(\n",
    "    config.model_settings.video_data_dir,\n",
    "    \"train\"\n",
    ")\n",
    "TEST_DIR = os.path.join(\n",
    "    config.model_settings.video_data_dir,\n",
    "    \"test\"\n",
    ")\n",
    "VALIDATION_DIR = os.path.join(\n",
    "    config.model_settings.video_data_dir,\n",
    "    \"validation\"\n",
    ")\n",
    "\n",
    "\n",
    "train_video_data_loader = VideoDataLoader(\n",
    "    path=TRAIN_DIR,\n",
    ")\n",
    "test_video_data_loader = VideoDataLoader(\n",
    "    path=TEST_DIR,\n",
    ")\n",
    "validation_video_data_loader = VideoDataLoader(\n",
    "    path=VALIDATION_DIR,\n",
    ")\n",
    "\n",
    "\n",
    "train_dataset = VideoDataset(\n",
    "    video_data_loader=train_video_data_loader,\n",
    "    normalization_type=\"across_frames\",\n",
    "    EAR_ratio=EAR_RATIO,\n",
    "    # transform=default_augmentation_pipeline(target_len=16, noise_std=0.02),\n",
    ")\n",
    "test_dataset = VideoDataset(\n",
    "    video_data_loader=test_video_data_loader,\n",
    "    normalization_type=\"across_frames\",\n",
    "    EAR_ratio=EAR_RATIO,\n",
    ")\n",
    "validation_dataset = VideoDataset(\n",
    "    video_data_loader=validation_video_data_loader,\n",
    "    normalization_type=\"across_frames\",\n",
    "    EAR_ratio=EAR_RATIO,\n",
    ")\n",
    "\n",
    "len(train_dataset)\n",
    "for _ in train_dataset:\n",
    "    pass\n",
    "len(train_dataset.labels_map)\n",
    "\n",
    "len(test_dataset)\n",
    "for _ in test_dataset:\n",
    "    pass\n",
    "\n",
    "len(validation_dataset)\n",
    "for _ in validation_dataset:\n",
    "    pass\n",
    "\n",
    "\n",
    "display(len(test_dataset.labels_map))\n",
    "display(len(train_dataset.labels_map))\n",
    "display(len(validation_dataset.labels_map))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde5336f",
   "metadata": {},
   "source": [
    "**Splitting Train and Test Datasets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0c82257",
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_total = len(train_dataset)\n",
    "# num_train = int(0.8 * num_total)\n",
    "# num_test = num_total - num_train\n",
    "# train_dataset, test_dataset = random_split(train_dataset, [num_train, num_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef613137",
   "metadata": {},
   "source": [
    "**Creating Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "781f5692",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-21 22:48:15,717 - INFO - Model configuration: {'obj_in': 5, 'joint_in': 3, 'gat_hidden': 192, 'gat_out': 192, 'temporal_hidden': 192, 'num_classes': 15, 'dropout': 0.1, 'temporal_pooling': 'attn_pool', 'use_layer_norm': True, 'attention_pooling_heads': 4, 'temporal_transformer_heads': 4, 'use_object_branch': False, 'device': 'cpu'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "attn_heads = 4\n",
    "hidden_size = 192\n",
    "\n",
    "assert hidden_size % attn_heads == 0, \"Hidden size must be divisible by number of attention heads.\"\n",
    "\n",
    "har_model = MultiModalHARModel(\n",
    "    obj_in=train_dataset[0].graphs_objects[0].x.shape[1],\n",
    "    joint_in=train_dataset[0].graphs_joints[0].x.shape[1],\n",
    "    gat_hidden=hidden_size,\n",
    "    gat_out=hidden_size,\n",
    "    temporal_hidden=hidden_size,\n",
    "    num_classes=len(train_dataset.labels_map), \n",
    "    dropout=0.1,\n",
    "    temporal_pooling=\"attn_pool\",\n",
    "    attention_pooling_heads=attn_heads,\n",
    "    temporal_transformer_heads=attn_heads,\n",
    "    use_layer_norm=True,\n",
    "    use_object_branch=WITH_OBJECT_BRANCH, # Testing without object branch\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d8464c4",
   "metadata": {},
   "source": [
    "**Create Evaluate Function For Early Stopping**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a215b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from validation.quantitative_metrics import evaluate_model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def evaluate_model_with_auc(model, dataset):\n",
    "    return evaluate_model(model, dataset, device).accuracy\n",
    "\n",
    "def evaluate(model, dataset):\n",
    "    import torch\n",
    "    device = 'cpu'\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i in range(len(dataset)):\n",
    "            sample = dataset[i]\n",
    "            label = sample.label.to(device)\n",
    "\n",
    "            # Move all graph tensors to device\n",
    "            graphs_objects = [g.to(device) for g in sample.graphs_objects]\n",
    "            graphs_joints = [g.to(device) for g in sample.graphs_joints]\n",
    "\n",
    "            # Forward pass\n",
    "            output = model(graphs_objects, graphs_joints)\n",
    "\n",
    "            # Compute prediction\n",
    "            if output.dim() == 1:\n",
    "                predicted = torch.argmax(output).unsqueeze(0)\n",
    "            else:\n",
    "                _, predicted = torch.max(output, dim=1)\n",
    "\n",
    "            correct += (predicted == label).sum().item()\n",
    "            total += 1\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f3ecc27",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_params = EarlyStoppingParams(\n",
    "    patience=20,\n",
    "    min_delta=1e-4,\n",
    "    mode='max',\n",
    "    evaluation_function=evaluate_model_with_auc,\n",
    "    evaluation_dataset=validation_dataset,\n",
    "    # evaluation_dataset=test_dataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bdc50bcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-21 22:48:18,279 - INFO - Starting training loop...\n",
      "2025-12-21 22:48:18,281 - INFO - Using weight decay: 0.0001\n",
      "2025-12-21 22:48:18,282 - INFO - Using early stopping\n",
      "2025-12-21 22:48:18,282 - INFO - Using Label Smoothing Cross Entropy with smoothing=0.1\n",
      "Epoch 1/120:   0%|          | 0/1860 [00:00<?, ?it/s]/Users/guilhermeleonardonunes/temp/masters-implementation/model/.venv/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:192: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\n",
      "Epoch 1/120: 100%|██████████| 1860/1860 [00:49<00:00, 37.58it/s]\n",
      "2025-12-21 22:49:07,793 - INFO - Evaluating for early stopping...\n",
      "Evaluating: 100%|██████████| 240/240 [00:01<00:00, 138.03it/s]\n",
      "2025-12-21 22:49:09,556 - INFO - Epoch 1/120, Loss: 2.5587\n",
      "Epoch 2/120: 100%|██████████| 1860/1860 [00:49<00:00, 37.68it/s]\n",
      "2025-12-21 22:49:58,926 - INFO - Evaluating for early stopping...\n",
      "Evaluating: 100%|██████████| 240/240 [00:01<00:00, 142.33it/s]\n",
      "2025-12-21 22:50:00,635 - INFO - Epoch 2/120, Loss: 2.4370\n",
      "Epoch 3/120: 100%|██████████| 1860/1860 [00:50<00:00, 37.10it/s]\n",
      "2025-12-21 22:50:50,775 - INFO - Evaluating for early stopping...\n",
      "Evaluating: 100%|██████████| 240/240 [00:01<00:00, 135.51it/s]\n",
      "2025-12-21 22:50:52,562 - INFO - Epoch 3/120, Loss: 2.3854\n",
      "Epoch 4/120: 100%|██████████| 1860/1860 [00:49<00:00, 37.36it/s]\n",
      "2025-12-21 22:51:42,347 - INFO - Evaluating for early stopping...\n",
      "Evaluating: 100%|██████████| 240/240 [00:01<00:00, 140.97it/s]\n",
      "2025-12-21 22:51:44,066 - INFO - Epoch 4/120, Loss: 2.3442\n",
      "Epoch 5/120: 100%|██████████| 1860/1860 [00:49<00:00, 37.49it/s]\n",
      "2025-12-21 22:52:33,678 - INFO - Evaluating for early stopping...\n",
      "Evaluating: 100%|██████████| 240/240 [00:01<00:00, 144.58it/s]\n",
      "2025-12-21 22:52:35,363 - INFO - Epoch 5/120, Loss: 2.3066\n",
      "Epoch 6/120: 100%|██████████| 1860/1860 [00:49<00:00, 37.42it/s]\n",
      "2025-12-21 22:53:25,077 - INFO - Evaluating for early stopping...\n",
      "Evaluating: 100%|██████████| 240/240 [00:01<00:00, 144.02it/s]\n",
      "2025-12-21 22:53:26,754 - INFO - Epoch 6/120, Loss: 2.2936\n",
      "Epoch 7/120: 100%|██████████| 1860/1860 [00:49<00:00, 37.47it/s]\n",
      "2025-12-21 22:54:16,396 - INFO - Evaluating for early stopping...\n",
      "Evaluating: 100%|██████████| 240/240 [00:01<00:00, 141.21it/s]\n",
      "2025-12-21 22:54:18,107 - INFO - Epoch 7/120, Loss: 2.2643\n",
      "Epoch 8/120: 100%|██████████| 1860/1860 [00:49<00:00, 37.28it/s]\n",
      "2025-12-21 22:55:07,996 - INFO - Evaluating for early stopping...\n",
      "Evaluating: 100%|██████████| 240/240 [00:01<00:00, 142.64it/s]\n",
      "2025-12-21 22:55:09,695 - INFO - Epoch 8/120, Loss: 2.2395\n",
      "Epoch 9/120: 100%|██████████| 1860/1860 [00:49<00:00, 37.43it/s]\n",
      "2025-12-21 22:55:59,392 - INFO - Evaluating for early stopping...\n",
      "Evaluating: 100%|██████████| 240/240 [00:01<00:00, 133.42it/s]\n",
      "2025-12-21 22:56:01,204 - INFO - Epoch 9/120, Loss: 2.2290\n",
      "Epoch 10/120: 100%|██████████| 1860/1860 [00:49<00:00, 37.21it/s]\n",
      "2025-12-21 22:56:51,197 - INFO - Evaluating for early stopping...\n",
      "Evaluating: 100%|██████████| 240/240 [00:01<00:00, 143.42it/s]\n",
      "2025-12-21 22:56:52,884 - INFO - Epoch 10/120, Loss: 2.2142\n",
      "Epoch 11/120: 100%|██████████| 1860/1860 [00:49<00:00, 37.26it/s]\n",
      "2025-12-21 22:57:42,808 - INFO - Evaluating for early stopping...\n",
      "Evaluating: 100%|██████████| 240/240 [00:01<00:00, 141.37it/s]\n",
      "2025-12-21 22:57:44,517 - INFO - Epoch 11/120, Loss: 2.1973\n",
      "Epoch 12/120: 100%|██████████| 1860/1860 [00:50<00:00, 37.01it/s]\n",
      "2025-12-21 22:58:34,774 - INFO - Evaluating for early stopping...\n",
      "Evaluating: 100%|██████████| 240/240 [00:01<00:00, 137.58it/s]\n",
      "2025-12-21 22:58:36,535 - INFO - Epoch 12/120, Loss: 2.1870\n",
      "Epoch 13/120: 100%|██████████| 1860/1860 [16:18<00:00,  1.90it/s] \n",
      "2025-12-21 23:14:55,100 - INFO - Evaluating for early stopping...\n",
      "Evaluating: 100%|██████████| 240/240 [00:01<00:00, 144.34it/s]\n",
      "2025-12-21 23:14:56,774 - INFO - Epoch 13/120, Loss: 2.1649\n",
      "Epoch 14/120: 100%|██████████| 1860/1860 [03:51<00:00,  8.04it/s]\n",
      "2025-12-21 23:18:48,151 - INFO - Evaluating for early stopping...\n",
      "Evaluating: 100%|██████████| 240/240 [00:01<00:00, 133.44it/s]\n",
      "2025-12-21 23:18:49,989 - INFO - Epoch 14/120, Loss: 2.1521\n",
      "Epoch 15/120: 100%|██████████| 1860/1860 [00:51<00:00, 36.44it/s]\n",
      "2025-12-21 23:19:41,035 - INFO - Evaluating for early stopping...\n",
      "Evaluating: 100%|██████████| 240/240 [00:01<00:00, 145.80it/s]\n",
      "2025-12-21 23:19:42,694 - INFO - Epoch 15/120, Loss: 2.1250\n",
      "Epoch 16/120: 100%|██████████| 1860/1860 [00:49<00:00, 37.33it/s]\n",
      "2025-12-21 23:20:32,523 - INFO - Evaluating for early stopping...\n",
      "Evaluating: 100%|██████████| 240/240 [00:01<00:00, 140.81it/s]\n",
      "2025-12-21 23:20:34,238 - INFO - Epoch 16/120, Loss: 2.1131\n",
      "Epoch 17/120: 100%|██████████| 1860/1860 [00:50<00:00, 37.17it/s]\n",
      "2025-12-21 23:21:24,287 - INFO - Evaluating for early stopping...\n",
      "Evaluating: 100%|██████████| 240/240 [00:01<00:00, 144.23it/s]\n",
      "2025-12-21 23:21:25,970 - INFO - Epoch 17/120, Loss: 2.1053\n",
      "Epoch 18/120: 100%|██████████| 1860/1860 [00:48<00:00, 38.32it/s]\n",
      "2025-12-21 23:22:14,515 - INFO - Evaluating for early stopping...\n",
      "Evaluating: 100%|██████████| 240/240 [00:01<00:00, 144.75it/s]\n",
      "2025-12-21 23:22:16,185 - INFO - Epoch 18/120, Loss: 2.0767\n",
      "Epoch 19/120: 100%|██████████| 1860/1860 [00:49<00:00, 37.33it/s]\n",
      "2025-12-21 23:23:06,013 - INFO - Evaluating for early stopping...\n",
      "Evaluating: 100%|██████████| 240/240 [00:01<00:00, 130.43it/s]\n",
      "2025-12-21 23:23:07,871 - INFO - Epoch 19/120, Loss: 2.0711\n",
      "Epoch 20/120: 100%|██████████| 1860/1860 [00:50<00:00, 36.87it/s]\n",
      "2025-12-21 23:23:58,321 - INFO - Evaluating for early stopping...\n",
      "Evaluating: 100%|██████████| 240/240 [00:01<00:00, 142.15it/s]\n",
      "2025-12-21 23:24:00,021 - INFO - Epoch 20/120, Loss: 2.0503\n",
      "Epoch 21/120: 100%|██████████| 1860/1860 [00:50<00:00, 36.95it/s]\n",
      "2025-12-21 23:24:50,355 - INFO - Evaluating for early stopping...\n",
      "Evaluating: 100%|██████████| 240/240 [00:01<00:00, 144.99it/s]\n",
      "2025-12-21 23:24:52,026 - INFO - Epoch 21/120, Loss: 2.0281\n",
      "Epoch 22/120: 100%|██████████| 1860/1860 [00:49<00:00, 37.26it/s]\n",
      "2025-12-21 23:25:41,947 - INFO - Evaluating for early stopping...\n",
      "Evaluating: 100%|██████████| 240/240 [00:01<00:00, 141.66it/s]\n",
      "2025-12-21 23:25:43,652 - INFO - Epoch 22/120, Loss: 2.0193\n",
      "Epoch 23/120: 100%|██████████| 1860/1860 [00:49<00:00, 37.23it/s]\n",
      "2025-12-21 23:26:33,611 - INFO - Evaluating for early stopping...\n",
      "Evaluating: 100%|██████████| 240/240 [00:01<00:00, 142.01it/s]\n",
      "2025-12-21 23:26:35,312 - INFO - Epoch 23/120, Loss: 1.9918\n",
      "Epoch 24/120: 100%|██████████| 1860/1860 [00:50<00:00, 36.76it/s]\n",
      "2025-12-21 23:27:25,913 - INFO - Evaluating for early stopping...\n",
      "Evaluating: 100%|██████████| 240/240 [00:01<00:00, 140.08it/s]\n",
      "2025-12-21 23:27:27,645 - INFO - Epoch 24/120, Loss: 1.9781\n",
      "Epoch 25/120: 100%|██████████| 1860/1860 [00:50<00:00, 37.20it/s]\n",
      "2025-12-21 23:28:17,652 - INFO - Evaluating for early stopping...\n",
      "Evaluating: 100%|██████████| 240/240 [00:01<00:00, 135.67it/s]\n",
      "2025-12-21 23:28:19,433 - INFO - Epoch 25/120, Loss: 1.9655\n",
      "Epoch 26/120: 100%|██████████| 1860/1860 [00:50<00:00, 37.08it/s]\n",
      "2025-12-21 23:29:09,600 - INFO - Evaluating for early stopping...\n",
      "Evaluating: 100%|██████████| 240/240 [00:01<00:00, 139.98it/s]\n",
      "2025-12-21 23:29:11,343 - INFO - Epoch 26/120, Loss: 1.9392\n",
      "Epoch 27/120: 100%|██████████| 1860/1860 [00:49<00:00, 37.47it/s]\n",
      "2025-12-21 23:30:00,991 - INFO - Evaluating for early stopping...\n",
      "Evaluating: 100%|██████████| 240/240 [00:01<00:00, 141.27it/s]\n",
      "2025-12-21 23:30:02,707 - INFO - Epoch 27/120, Loss: 1.9173\n",
      "Epoch 28/120: 100%|██████████| 1860/1860 [00:50<00:00, 36.67it/s]\n",
      "2025-12-21 23:30:53,428 - INFO - Evaluating for early stopping...\n",
      "Evaluating: 100%|██████████| 240/240 [00:01<00:00, 142.68it/s]\n",
      "2025-12-21 23:30:55,120 - INFO - Epoch 28/120, Loss: 1.9062\n",
      "Epoch 29/120: 100%|██████████| 1860/1860 [00:50<00:00, 37.05it/s]\n",
      "2025-12-21 23:31:45,325 - INFO - Evaluating for early stopping...\n",
      "Evaluating: 100%|██████████| 240/240 [00:01<00:00, 143.72it/s]\n",
      "2025-12-21 23:31:47,012 - INFO - Epoch 29/120, Loss: 1.8656\n",
      "Epoch 30/120: 100%|██████████| 1860/1860 [00:51<00:00, 36.28it/s]\n",
      "2025-12-21 23:32:38,286 - INFO - Evaluating for early stopping...\n",
      "Evaluating: 100%|██████████| 240/240 [00:01<00:00, 146.42it/s]\n",
      "2025-12-21 23:32:39,936 - INFO - Epoch 30/120, Loss: 1.8447\n",
      "Epoch 31/120: 100%|██████████| 1860/1860 [00:49<00:00, 37.30it/s]\n",
      "2025-12-21 23:33:29,800 - INFO - Evaluating for early stopping...\n",
      "Evaluating: 100%|██████████| 240/240 [00:01<00:00, 142.56it/s]\n",
      "2025-12-21 23:33:31,496 - INFO - Epoch 31/120, Loss: 1.8201\n",
      "Epoch 32/120: 100%|██████████| 1860/1860 [00:50<00:00, 37.09it/s]\n",
      "2025-12-21 23:34:21,644 - INFO - Evaluating for early stopping...\n",
      "Evaluating: 100%|██████████| 240/240 [00:01<00:00, 143.60it/s]\n",
      "2025-12-21 23:34:23,330 - INFO - Epoch 32/120, Loss: 1.7943\n",
      "Epoch 33/120: 100%|██████████| 1860/1860 [00:50<00:00, 36.94it/s]\n",
      "2025-12-21 23:35:13,686 - INFO - Evaluating for early stopping...\n",
      "Evaluating: 100%|██████████| 240/240 [00:01<00:00, 135.63it/s]\n",
      "2025-12-21 23:35:15,467 - INFO - Epoch 33/120, Loss: 1.7603\n",
      "Epoch 34/120: 100%|██████████| 1860/1860 [00:50<00:00, 36.88it/s]\n",
      "2025-12-21 23:36:05,906 - INFO - Evaluating for early stopping...\n",
      "Evaluating: 100%|██████████| 240/240 [00:01<00:00, 140.05it/s]\n",
      "2025-12-21 23:36:07,631 - INFO - Epoch 34/120, Loss: 1.7389\n",
      "Epoch 35/120: 100%|██████████| 1860/1860 [00:50<00:00, 36.99it/s]\n",
      "2025-12-21 23:36:57,914 - INFO - Evaluating for early stopping...\n",
      "Evaluating: 100%|██████████| 240/240 [00:01<00:00, 142.87it/s]\n",
      "2025-12-21 23:36:59,606 - INFO - Epoch 35/120, Loss: 1.7145\n",
      "Epoch 36/120: 100%|██████████| 1860/1860 [00:50<00:00, 37.03it/s]\n",
      "2025-12-21 23:37:49,834 - INFO - Evaluating for early stopping...\n",
      "Evaluating: 100%|██████████| 240/240 [00:01<00:00, 142.13it/s]\n",
      "2025-12-21 23:37:51,537 - INFO - Epoch 36/120, Loss: 1.6845\n",
      "Epoch 37/120: 100%|██████████| 1860/1860 [00:50<00:00, 37.19it/s]\n",
      "2025-12-21 23:38:41,558 - INFO - Evaluating for early stopping...\n",
      "Evaluating: 100%|██████████| 240/240 [00:01<00:00, 142.28it/s]\n",
      "2025-12-21 23:38:43,258 - INFO - Epoch 37/120, Loss: 1.6659\n",
      "Epoch 38/120: 100%|██████████| 1860/1860 [00:50<00:00, 37.01it/s]\n",
      "2025-12-21 23:39:33,516 - INFO - Evaluating for early stopping...\n",
      "Evaluating: 100%|██████████| 240/240 [00:01<00:00, 141.28it/s]\n",
      "2025-12-21 23:39:35,229 - INFO - Epoch 38/120, Loss: 1.6591\n",
      "Epoch 39/120: 100%|██████████| 1860/1860 [00:50<00:00, 36.53it/s]\n",
      "2025-12-21 23:40:26,146 - INFO - Evaluating for early stopping...\n",
      "Evaluating: 100%|██████████| 240/240 [00:01<00:00, 132.80it/s]\n",
      "2025-12-21 23:40:27,968 - INFO - Epoch 39/120, Loss: 1.6093\n",
      "Epoch 40/120: 100%|██████████| 1860/1860 [00:50<00:00, 36.76it/s]\n",
      "2025-12-21 23:41:18,563 - INFO - Evaluating for early stopping...\n",
      "Evaluating: 100%|██████████| 240/240 [00:01<00:00, 141.98it/s]\n",
      "2025-12-21 23:41:20,271 - INFO - Epoch 40/120, Loss: 1.5871\n",
      "Epoch 41/120: 100%|██████████| 1860/1860 [00:50<00:00, 37.15it/s]\n",
      "2025-12-21 23:42:10,344 - INFO - Evaluating for early stopping...\n",
      "Evaluating: 100%|██████████| 240/240 [00:01<00:00, 140.53it/s]\n",
      "2025-12-21 23:42:12,063 - INFO - Epoch 41/120, Loss: 1.5477\n",
      "Epoch 42/120: 100%|██████████| 1860/1860 [00:50<00:00, 36.94it/s]\n",
      "2025-12-21 23:43:02,416 - INFO - Evaluating for early stopping...\n",
      "Evaluating: 100%|██████████| 240/240 [00:01<00:00, 137.73it/s]\n",
      "2025-12-21 23:43:04,179 - INFO - Epoch 42/120, Loss: 1.5438\n",
      "Epoch 43/120: 100%|██████████| 1860/1860 [00:50<00:00, 37.13it/s]\n",
      "2025-12-21 23:43:54,277 - INFO - Evaluating for early stopping...\n",
      "Evaluating: 100%|██████████| 240/240 [00:01<00:00, 143.59it/s]\n",
      "2025-12-21 23:43:55,960 - INFO - Epoch 43/120, Loss: 1.5091\n",
      "Epoch 44/120: 100%|██████████| 1860/1860 [00:49<00:00, 37.61it/s]\n",
      "2025-12-21 23:44:45,420 - INFO - Evaluating for early stopping...\n",
      "Evaluating: 100%|██████████| 240/240 [00:01<00:00, 143.53it/s]\n",
      "2025-12-21 23:44:47,103 - INFO - Epoch 44/120, Loss: 1.4900\n",
      "Epoch 45/120: 100%|██████████| 1860/1860 [00:50<00:00, 36.86it/s]\n",
      "2025-12-21 23:45:37,567 - INFO - Evaluating for early stopping...\n",
      "Evaluating: 100%|██████████| 240/240 [00:01<00:00, 140.05it/s]\n",
      "2025-12-21 23:45:39,292 - INFO - Epoch 45/120, Loss: 1.4524\n",
      "Epoch 46/120: 100%|██████████| 1860/1860 [00:50<00:00, 37.14it/s]\n",
      "2025-12-21 23:46:29,369 - INFO - Evaluating for early stopping...\n",
      "Evaluating: 100%|██████████| 240/240 [00:01<00:00, 135.51it/s]\n",
      "2025-12-21 23:46:31,154 - INFO - Epoch 46/120, Loss: 1.4393\n",
      "Epoch 47/120: 100%|██████████| 1860/1860 [00:50<00:00, 37.03it/s]\n",
      "2025-12-21 23:47:21,384 - INFO - Evaluating for early stopping...\n",
      "Evaluating: 100%|██████████| 240/240 [00:01<00:00, 142.41it/s]\n",
      "2025-12-21 23:47:23,084 - INFO - Epoch 47/120, Loss: 1.4218\n",
      "Epoch 48/120: 100%|██████████| 1860/1860 [00:50<00:00, 36.91it/s]\n",
      "2025-12-21 23:48:13,483 - INFO - Evaluating for early stopping...\n",
      "Evaluating: 100%|██████████| 240/240 [00:01<00:00, 141.16it/s]\n",
      "2025-12-21 23:48:15,194 - INFO - Epoch 48/120, Loss: 1.3825\n",
      "Epoch 49/120: 100%|██████████| 1860/1860 [00:50<00:00, 36.56it/s]\n",
      "2025-12-21 23:49:06,068 - INFO - Evaluating for early stopping...\n",
      "Evaluating: 100%|██████████| 240/240 [00:01<00:00, 138.64it/s]\n",
      "2025-12-21 23:49:07,814 - INFO - Epoch 49/120, Loss: 1.3611\n",
      "Epoch 50/120: 100%|██████████| 1860/1860 [00:50<00:00, 36.71it/s]\n",
      "2025-12-21 23:49:58,476 - INFO - Evaluating for early stopping...\n",
      "Evaluating: 100%|██████████| 240/240 [00:01<00:00, 140.35it/s]\n",
      "2025-12-21 23:50:00,200 - INFO - Epoch 50/120, Loss: 1.3428\n",
      "Epoch 51/120: 100%|██████████| 1860/1860 [00:51<00:00, 36.46it/s]\n",
      "2025-12-21 23:50:51,210 - INFO - Evaluating for early stopping...\n",
      "Evaluating: 100%|██████████| 240/240 [00:01<00:00, 130.86it/s]\n",
      "2025-12-21 23:50:53,055 - INFO - Epoch 51/120, Loss: 1.3316\n",
      "Epoch 52/120: 100%|██████████| 1860/1860 [16:22<00:00,  1.89it/s]  \n",
      "2025-12-22 00:07:15,266 - INFO - Evaluating for early stopping...\n",
      "Evaluating: 100%|██████████| 240/240 [00:01<00:00, 141.55it/s]\n",
      "2025-12-22 00:07:16,979 - INFO - Epoch 52/120, Loss: 1.2841\n",
      "Epoch 53/120: 100%|██████████| 1860/1860 [00:50<00:00, 36.81it/s]\n",
      "2025-12-22 00:08:07,512 - INFO - Evaluating for early stopping...\n",
      "Evaluating: 100%|██████████| 240/240 [00:01<00:00, 141.86it/s]\n",
      "2025-12-22 00:08:09,217 - INFO - Epoch 53/120, Loss: 1.2930\n",
      "Epoch 54/120: 100%|██████████| 1860/1860 [03:40<00:00,  8.43it/s] \n",
      "2025-12-22 00:11:49,896 - INFO - Evaluating for early stopping...\n",
      "Evaluating: 100%|██████████| 240/240 [00:05<00:00, 41.51it/s]\n",
      "2025-12-22 00:11:55,747 - INFO - Epoch 54/120, Loss: 1.2394\n",
      "Epoch 55/120: 100%|██████████| 1860/1860 [32:58<00:00,  1.06s/it]   \n",
      "2025-12-22 00:44:54,368 - INFO - Evaluating for early stopping...\n",
      "Evaluating: 100%|██████████| 240/240 [15:27<00:00,  3.87s/it]\n",
      "2025-12-22 01:00:22,369 - INFO - Epoch 55/120, Loss: 1.2316\n",
      "Epoch 56/120: 100%|██████████| 1860/1860 [03:38<00:00,  8.50it/s] \n",
      "2025-12-22 01:04:01,241 - INFO - Evaluating for early stopping...\n",
      "Evaluating: 100%|██████████| 240/240 [00:04<00:00, 48.87it/s]\n",
      "2025-12-22 01:04:06,187 - INFO - Epoch 56/120, Loss: 1.2069\n",
      "Epoch 57/120: 100%|██████████| 1860/1860 [34:18<00:00,  1.11s/it]   \n",
      "2025-12-22 01:38:25,116 - INFO - Evaluating for early stopping...\n",
      "Evaluating: 100%|██████████| 240/240 [00:02<00:00, 95.85it/s] \n",
      "2025-12-22 01:38:27,636 - INFO - Epoch 57/120, Loss: 1.1835\n",
      "Epoch 58/120: 100%|██████████| 1860/1860 [32:59<00:00,  1.06s/it]  \n",
      "2025-12-22 02:11:27,633 - INFO - Evaluating for early stopping...\n",
      "Evaluating: 100%|██████████| 240/240 [00:08<00:00, 29.14it/s]\n",
      "2025-12-22 02:11:35,955 - INFO - Epoch 58/120, Loss: 1.1953\n",
      "Epoch 59/120: 100%|██████████| 1860/1860 [35:20<00:00,  1.14s/it]  \n",
      "2025-12-22 02:46:56,415 - INFO - Evaluating for early stopping...\n",
      "Evaluating: 100%|██████████| 240/240 [00:01<00:00, 140.16it/s]\n",
      "2025-12-22 02:46:58,153 - INFO - Epoch 59/120, Loss: 1.1529\n",
      "Epoch 60/120: 100%|██████████| 1860/1860 [33:02<00:00,  1.07s/it]   \n",
      "2025-12-22 03:20:00,597 - INFO - Evaluating for early stopping...\n",
      "Evaluating: 100%|██████████| 240/240 [00:05<00:00, 47.98it/s]\n",
      "2025-12-22 03:20:05,628 - INFO - Epoch 60/120, Loss: 1.1550\n",
      "Epoch 61/120: 100%|██████████| 1860/1860 [48:28<00:00,  1.56s/it]  \n",
      "2025-12-22 04:08:34,363 - INFO - Evaluating for early stopping...\n",
      "Evaluating: 100%|██████████| 240/240 [00:05<00:00, 44.12it/s]\n",
      "2025-12-22 04:08:39,844 - INFO - Epoch 61/120, Loss: 1.1196\n",
      "Epoch 62/120: 100%|██████████| 1860/1860 [36:18<00:00,  1.17s/it]  \n",
      "2025-12-22 04:44:58,393 - INFO - Evaluating for early stopping...\n",
      "Evaluating: 100%|██████████| 240/240 [00:01<00:00, 135.44it/s]\n",
      "2025-12-22 04:45:00,176 - INFO - Epoch 62/120, Loss: 1.1149\n",
      "Epoch 63/120: 100%|██████████| 1860/1860 [19:14<00:00,  1.61it/s]  \n",
      "2025-12-22 05:04:15,118 - INFO - Evaluating for early stopping...\n",
      "Evaluating: 100%|██████████| 240/240 [00:05<00:00, 45.53it/s]\n",
      "2025-12-22 05:04:20,443 - INFO - Epoch 63/120, Loss: 1.1102\n",
      "Epoch 64/120: 100%|██████████| 1860/1860 [33:41<00:00,  1.09s/it]  \n",
      "2025-12-22 05:38:02,087 - INFO - Evaluating for early stopping...\n",
      "Evaluating: 100%|██████████| 240/240 [00:02<00:00, 90.09it/s] \n",
      "2025-12-22 05:38:04,768 - INFO - Epoch 64/120, Loss: 1.1131\n",
      "Epoch 65/120: 100%|██████████| 1860/1860 [20:58<00:00,  1.48it/s]  \n",
      "2025-12-22 05:59:03,374 - INFO - Evaluating for early stopping...\n",
      "Evaluating: 100%|██████████| 240/240 [00:05<00:00, 46.93it/s]\n",
      "2025-12-22 05:59:08,522 - INFO - Epoch 65/120, Loss: 1.0762\n",
      "Epoch 66/120: 100%|██████████| 1860/1860 [20:21<00:00,  1.52it/s]  \n",
      "2025-12-22 06:19:29,901 - INFO - Evaluating for early stopping...\n",
      "Evaluating: 100%|██████████| 240/240 [00:03<00:00, 64.15it/s] \n",
      "2025-12-22 06:19:33,668 - INFO - Epoch 66/120, Loss: 1.0514\n",
      "Epoch 67/120: 100%|██████████| 1860/1860 [36:06<00:00,  1.16s/it]   \n",
      "2025-12-22 06:55:40,093 - INFO - Evaluating for early stopping...\n",
      "Evaluating: 100%|██████████| 240/240 [00:01<00:00, 137.65it/s]\n",
      "2025-12-22 06:55:41,851 - INFO - Epoch 67/120, Loss: 1.0444\n",
      "Epoch 68/120: 100%|██████████| 1860/1860 [33:14<00:00,  1.07s/it]   \n",
      "2025-12-22 07:28:55,928 - INFO - Evaluating for early stopping...\n",
      "Evaluating: 100%|██████████| 240/240 [00:02<00:00, 103.98it/s]\n",
      "2025-12-22 07:28:58,251 - INFO - Epoch 68/120, Loss: 1.0204\n",
      "Epoch 69/120: 100%|██████████| 1860/1860 [28:21<00:00,  1.09it/s]  \n",
      "2025-12-22 07:57:19,272 - INFO - Evaluating for early stopping...\n",
      "Evaluating: 100%|██████████| 240/240 [00:05<00:00, 47.36it/s]\n",
      "2025-12-22 07:57:24,377 - INFO - Epoch 69/120, Loss: 0.9939\n",
      "Epoch 70/120: 100%|██████████| 1860/1860 [06:17<00:00,  4.92it/s]  \n",
      "2025-12-22 08:03:42,250 - INFO - Evaluating for early stopping...\n",
      "Evaluating: 100%|██████████| 240/240 [00:01<00:00, 121.24it/s]\n",
      "2025-12-22 08:03:44,245 - INFO - Epoch 70/120, Loss: 1.0185\n",
      "Epoch 71/120: 100%|██████████| 1860/1860 [33:23<00:00,  1.08s/it]   \n",
      "2025-12-22 08:37:08,189 - INFO - Evaluating for early stopping...\n",
      "Evaluating: 100%|██████████| 240/240 [00:05<00:00, 44.37it/s]\n",
      "2025-12-22 08:37:13,659 - INFO - Epoch 71/120, Loss: 1.0067\n",
      "Epoch 72/120: 100%|██████████| 1860/1860 [21:11<00:00,  1.46it/s]  \n",
      "2025-12-22 08:58:24,759 - INFO - Evaluating for early stopping...\n",
      "Evaluating: 100%|██████████| 240/240 [04:22<00:00,  1.09s/it]\n",
      "2025-12-22 09:02:47,516 - INFO - Epoch 72/120, Loss: 0.9548\n",
      "Epoch 73/120: 100%|██████████| 1860/1860 [07:05<00:00,  4.37it/s]  \n",
      "2025-12-22 09:09:53,141 - INFO - Evaluating for early stopping...\n",
      "Evaluating: 100%|██████████| 240/240 [00:01<00:00, 141.54it/s]\n",
      "2025-12-22 09:09:54,848 - INFO - Epoch 73/120, Loss: 0.9501\n",
      "Epoch 74/120: 100%|██████████| 1860/1860 [00:53<00:00, 34.68it/s]\n",
      "2025-12-22 09:10:48,488 - INFO - Evaluating for early stopping...\n",
      "Evaluating: 100%|██████████| 240/240 [00:01<00:00, 135.98it/s]\n",
      "2025-12-22 09:10:50,263 - INFO - Epoch 74/120, Loss: 0.9907\n",
      "Epoch 75/120: 100%|██████████| 1860/1860 [00:50<00:00, 36.48it/s]\n",
      "2025-12-22 09:11:41,246 - INFO - Evaluating for early stopping...\n",
      "Evaluating: 100%|██████████| 240/240 [00:01<00:00, 133.68it/s]\n",
      "2025-12-22 09:11:43,058 - INFO - Epoch 75/120, Loss: 0.9504\n",
      "Epoch 76/120: 100%|██████████| 1860/1860 [00:51<00:00, 36.33it/s]\n",
      "2025-12-22 09:12:34,263 - INFO - Evaluating for early stopping...\n",
      "Evaluating: 100%|██████████| 240/240 [00:01<00:00, 138.79it/s]\n",
      "2025-12-22 09:12:36,003 - INFO - Epoch 76/120, Loss: 0.9423\n",
      "Epoch 77/120: 100%|██████████| 1860/1860 [00:50<00:00, 37.16it/s]\n",
      "2025-12-22 09:13:26,064 - INFO - Evaluating for early stopping...\n",
      "Evaluating: 100%|██████████| 240/240 [00:01<00:00, 139.80it/s]\n",
      "2025-12-22 09:13:27,792 - INFO - Epoch 77/120, Loss: 0.9250\n",
      "Epoch 78/120: 100%|██████████| 1860/1860 [00:49<00:00, 37.24it/s]\n",
      "2025-12-22 09:14:17,743 - INFO - Evaluating for early stopping...\n",
      "Evaluating: 100%|██████████| 240/240 [00:01<00:00, 142.31it/s]\n",
      "2025-12-22 09:14:19,441 - INFO - Epoch 78/120, Loss: 0.9462\n",
      "Epoch 79/120: 100%|██████████| 1860/1860 [00:49<00:00, 37.37it/s]\n",
      "2025-12-22 09:15:09,221 - INFO - Evaluating for early stopping...\n",
      "Evaluating: 100%|██████████| 240/240 [00:01<00:00, 139.02it/s]\n",
      "2025-12-22 09:15:10,958 - INFO - Epoch 79/120, Loss: 0.9299\n",
      "Epoch 80/120: 100%|██████████| 1860/1860 [00:50<00:00, 36.64it/s]\n",
      "2025-12-22 09:16:01,725 - INFO - Evaluating for early stopping...\n",
      "Evaluating: 100%|██████████| 240/240 [00:01<00:00, 141.19it/s]\n",
      "2025-12-22 09:16:03,437 - INFO - Epoch 80/120, Loss: 0.8982\n",
      "Epoch 81/120: 100%|██████████| 1860/1860 [00:50<00:00, 36.81it/s]\n",
      "2025-12-22 09:16:53,966 - INFO - Evaluating for early stopping...\n",
      "Evaluating: 100%|██████████| 240/240 [00:01<00:00, 141.15it/s]\n",
      "2025-12-22 09:16:55,679 - INFO - Epoch 81/120, Loss: 0.8921\n",
      "Epoch 82/120: 100%|██████████| 1860/1860 [00:50<00:00, 36.90it/s]\n",
      "2025-12-22 09:17:46,082 - INFO - Evaluating for early stopping...\n",
      "Evaluating: 100%|██████████| 240/240 [00:01<00:00, 136.54it/s]\n",
      "2025-12-22 09:17:47,851 - INFO - Epoch 82/120, Loss: 0.9038\n",
      "Epoch 83/120: 100%|██████████| 1860/1860 [00:50<00:00, 36.61it/s]\n",
      "2025-12-22 09:18:38,662 - INFO - Evaluating for early stopping...\n",
      "Evaluating: 100%|██████████| 240/240 [00:01<00:00, 139.36it/s]\n",
      "2025-12-22 09:18:40,398 - INFO - Epoch 83/120, Loss: 0.8962\n",
      "Epoch 84/120: 100%|██████████| 1860/1860 [00:50<00:00, 36.73it/s]\n",
      "2025-12-22 09:19:31,039 - INFO - Evaluating for early stopping...\n",
      "Evaluating: 100%|██████████| 240/240 [00:01<00:00, 137.36it/s]\n",
      "2025-12-22 09:19:32,798 - INFO - Epoch 84/120, Loss: 0.8648\n",
      "Epoch 85/120: 100%|██████████| 1860/1860 [00:50<00:00, 36.73it/s]\n",
      "2025-12-22 09:20:23,444 - INFO - Evaluating for early stopping...\n",
      "Evaluating: 100%|██████████| 240/240 [00:01<00:00, 120.82it/s]\n",
      "2025-12-22 09:20:25,444 - INFO - Epoch 85/120, Loss: 0.8742\n",
      "Epoch 86/120: 100%|██████████| 1860/1860 [02:03<00:00, 15.06it/s]\n",
      "2025-12-22 09:22:28,959 - INFO - Evaluating for early stopping...\n",
      "Evaluating: 100%|██████████| 240/240 [00:01<00:00, 141.80it/s]\n",
      "2025-12-22 09:22:30,671 - INFO - Epoch 86/120, Loss: 0.8823\n",
      "Epoch 87/120: 100%|██████████| 1860/1860 [00:49<00:00, 37.51it/s]\n",
      "2025-12-22 09:23:20,255 - INFO - Evaluating for early stopping...\n",
      "Evaluating: 100%|██████████| 240/240 [00:01<00:00, 138.08it/s]\n",
      "2025-12-22 09:23:22,005 - INFO - Epoch 87/120, Loss: 0.8257\n",
      "Epoch 88/120: 100%|██████████| 1860/1860 [00:49<00:00, 37.48it/s]\n",
      "2025-12-22 09:24:11,641 - INFO - Evaluating for early stopping...\n",
      "Evaluating: 100%|██████████| 240/240 [00:01<00:00, 143.54it/s]\n",
      "2025-12-22 09:24:13,324 - INFO - Epoch 88/120, Loss: 0.8662\n",
      "Epoch 89/120: 100%|██████████| 1860/1860 [00:50<00:00, 37.15it/s]\n",
      "2025-12-22 09:25:03,391 - INFO - Evaluating for early stopping...\n",
      "Evaluating: 100%|██████████| 240/240 [00:01<00:00, 140.09it/s]\n",
      "2025-12-22 09:25:05,116 - INFO - Epoch 89/120, Loss: 0.8384\n",
      "Epoch 90/120: 100%|██████████| 1860/1860 [00:50<00:00, 36.96it/s]\n",
      "2025-12-22 09:25:55,442 - INFO - Evaluating for early stopping...\n",
      "Evaluating: 100%|██████████| 240/240 [00:01<00:00, 139.61it/s]\n",
      "2025-12-22 09:25:57,173 - INFO - Epoch 90/120, Loss: 0.8495\n",
      "Epoch 91/120: 100%|██████████| 1860/1860 [00:50<00:00, 36.71it/s]\n",
      "2025-12-22 09:26:47,836 - INFO - Evaluating for early stopping...\n",
      "Evaluating: 100%|██████████| 240/240 [00:01<00:00, 142.63it/s]\n",
      "2025-12-22 09:26:49,530 - INFO - Epoch 91/120, Loss: 0.8234\n",
      "Epoch 92/120: 100%|██████████| 1860/1860 [00:50<00:00, 36.78it/s]\n",
      "2025-12-22 09:27:40,109 - INFO - Evaluating for early stopping...\n",
      "Evaluating: 100%|██████████| 240/240 [00:01<00:00, 134.96it/s]\n",
      "2025-12-22 09:27:41,901 - INFO - Epoch 92/120, Loss: 0.8714\n",
      "Epoch 93/120: 100%|██████████| 1860/1860 [00:50<00:00, 37.17it/s]\n",
      "2025-12-22 09:28:31,942 - INFO - Evaluating for early stopping...\n",
      "Evaluating: 100%|██████████| 240/240 [00:01<00:00, 135.67it/s]\n",
      "2025-12-22 09:28:33,736 - INFO - Epoch 93/120, Loss: 0.8038\n",
      "Epoch 94/120: 100%|██████████| 1860/1860 [00:50<00:00, 37.02it/s]\n",
      "2025-12-22 09:29:23,974 - INFO - Evaluating for early stopping...\n",
      "Evaluating: 100%|██████████| 240/240 [00:01<00:00, 135.30it/s]\n",
      "2025-12-22 09:29:25,759 - INFO - Epoch 94/120, Loss: 0.8152\n",
      "Epoch 95/120: 100%|██████████| 1860/1860 [00:50<00:00, 37.04it/s]\n",
      "2025-12-22 09:30:15,976 - INFO - Evaluating for early stopping...\n",
      "Evaluating: 100%|██████████| 240/240 [00:01<00:00, 135.73it/s]\n",
      "2025-12-22 09:30:17,755 - INFO - Early stopping triggered at epoch 95.\n",
      "2025-12-22 09:30:17,785 - INFO - Loaded best model state from early stopping.\n"
     ]
    }
   ],
   "source": [
    "from model.training_loop import WarmupSchedulerParams\n",
    "\n",
    "\n",
    "train_history = train(\n",
    "    model=har_model,\n",
    "    video_dataset=train_dataset,\n",
    "    device='cpu',\n",
    "    epochs=120,\n",
    "    # epochs=40,\n",
    "    # epochs=74,\n",
    "    # epochs=95,\n",
    "    lr=1e-4,\n",
    "    weight_decay=1e-4,\n",
    "    early_stopping=early_stopping_params,\n",
    "    warmup_scheduler_params=WarmupSchedulerParams(True, 400),\n",
    "    cross_entropy_label_smoothing=0.1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33cabcd9",
   "metadata": {},
   "source": [
    "## Training Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde2e009",
   "metadata": {},
   "source": [
    "**Early Stopping**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d6abf28",
   "metadata": {},
   "source": [
    "**Training**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd5bc8d",
   "metadata": {},
   "source": [
    "**Saving Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "66b74bb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-22 09:30:17,823 - INFO - Saving model to /Volumes/KODAK/masters/model/validation_datasets/NTU-RGBD-60/model/har_model_v1.0.1_ntu_rgbd_60_20_no_obj_20251222_093017.pht...\n",
      "2025-12-22 09:30:18,135 - INFO - Model saved successfully.\n"
     ]
    }
   ],
   "source": [
    "har_model.save(\n",
    "    training_history=train_history,\n",
    "    EAR_ratio=EAR_RATIO,\n",
    "    with_object_branch=WITH_OBJECT_BRANCH,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8bf73a0",
   "metadata": {},
   "source": [
    "## Running tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe0f60c1",
   "metadata": {},
   "source": [
    "**Accuracy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a102aee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 39.17%\n"
     ]
    }
   ],
   "source": [
    "accuracy_evaluation = evaluate(har_model, test_dataset)\n",
    "print(f\"Test Accuracy: {accuracy_evaluation:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "265d4d4d",
   "metadata": {},
   "source": [
    "## Debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1f9a2abf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out.shape torch.Size([1, 15])\n",
      "out device cpu label device cpu\n",
      "logits: [[-1.9525183 -4.1452556 -4.3876915 -3.8443375 -5.4894958 -6.487077\n",
      "  -6.1455264 -6.3223205 -5.362332  -5.89621   -6.015603  -5.5048246\n",
      "  -2.917143  -7.356536  -1.189119 ]]\n",
      "probs: [[0.24709427 0.02757839 0.02164115 0.03726113 0.00719073 0.00265173\n",
      "  0.00373132 0.00312667 0.00816581 0.00478783 0.00424901 0.00708134\n",
      "  0.09417409 0.00111155 0.53015494]]\n",
      "entropy: 1.4296892881393433\n",
      "pred: 14 label: 0\n"
     ]
    }
   ],
   "source": [
    "import torch, torch.nn.functional as F\n",
    "device = 'cpu'   # match training device\n",
    "har_model.to(device)\n",
    "har_model.eval()\n",
    "\n",
    "sample = train_dataset[0]\n",
    "graphs_objects = [g.to(device) for g in sample.graphs_objects]\n",
    "graphs_joints = [g.to(device) for g in sample.graphs_joints]\n",
    "label = sample.label.unsqueeze(0).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    out = har_model(graphs_objects, graphs_joints)   # expect [1, num_classes]\n",
    "    probs = F.softmax(out, dim=-1)\n",
    "    ent = -(probs * probs.log()).sum(dim=-1)     # entropy\n",
    "    pred = torch.argmax(probs, dim=-1)\n",
    "\n",
    "print(\"out.shape\", out.shape)\n",
    "print(\"out device\", out.device, \"label device\", label.device)\n",
    "print(\"logits:\", out.cpu().numpy())\n",
    "print(\"probs:\", probs.cpu().numpy())\n",
    "print(\"entropy:\", ent.item())\n",
    "print(\"pred:\", pred.item(), \"label:\", label.item())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a7199e",
   "metadata": {},
   "source": [
    "**Mapping Consistency - Distribution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9da92364",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TRAIN ===\n",
      "len: 1860\n",
      "unique labels: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]\n",
      "counts: Counter({0: 124, 1: 124, 2: 124, 3: 124, 4: 124, 5: 124, 6: 124, 7: 124, 8: 124, 9: 124, 10: 124, 11: 124, 12: 124, 13: 124, 14: 124})\n",
      "labels_map (sample): {'A001': 0, 'A002': 1, 'A004': 2, 'A006': 3, 'A011': 4, 'A012': 5, 'A013': 6, 'A014': 7, 'A015': 8, 'A020': 9, 'A021': 10, 'A028': 11, 'A029': 12, 'A030': 13, 'A032': 14}\n",
      "\n",
      "=== TEST ===\n",
      "len: 240\n",
      "unique labels: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]\n",
      "counts: Counter({0: 16, 1: 16, 2: 16, 3: 16, 4: 16, 5: 16, 6: 16, 7: 16, 8: 16, 9: 16, 10: 16, 11: 16, 12: 16, 13: 16, 14: 16})\n",
      "labels_map (sample): {'A001': 0, 'A002': 1, 'A004': 2, 'A006': 3, 'A011': 4, 'A012': 5, 'A013': 6, 'A014': 7, 'A015': 8, 'A020': 9, 'A021': 10, 'A028': 11, 'A029': 12, 'A030': 13, 'A032': 14}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "def inspect_dataset(dataset, name):\n",
    "    labels = [int(s.label) for s in dataset]\n",
    "    print(f\"=== {name} ===\")\n",
    "    print(\"len:\", len(labels))\n",
    "    print(\"unique labels:\", sorted(set(labels)))\n",
    "    print(\"counts:\", Counter(labels))\n",
    "    print(\"labels_map (sample):\", getattr(dataset, \"labels_map\", None))\n",
    "    print()\n",
    "\n",
    "inspect_dataset(train_dataset, \"TRAIN\")\n",
    "inspect_dataset(test_dataset, \"TEST\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a023a48",
   "metadata": {},
   "source": [
    "**Prediction Distribution - Predicts only few classes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ac297c99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred distribution: Counter({0: 23, 2: 23, 10: 22, 7: 21, 4: 20, 3: 20, 5: 19, 6: 16, 12: 14, 14: 11, 9: 11, 13: 11, 8: 11, 1: 10, 11: 8})\n",
      "true distribution : Counter({0: 16, 1: 16, 2: 16, 3: 16, 4: 16, 5: 16, 6: 16, 7: 16, 8: 16, 9: 16, 10: 16, 11: 16, 12: 16, 13: 16, 14: 16})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import torch, torch.nn.functional as F\n",
    "\n",
    "def pred_distribution(model, dataset, device='cpu'):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    truths = []\n",
    "    with torch.no_grad():\n",
    "        for s in dataset:\n",
    "            graphs_objects = [g.to(device) for g in s.graphs_objects]\n",
    "            graphs_joints  = [g.to(device) for g in s.graphs_joints]\n",
    "            out = model(graphs_objects, graphs_joints)  # [1, C]\n",
    "            preds.append(int(torch.argmax(out, dim=-1)))\n",
    "            truths.append(int(s.label))\n",
    "    print(\"pred distribution:\", Counter(preds))\n",
    "    print(\"true distribution :\", Counter(truths))\n",
    "    return preds, truths\n",
    "\n",
    "preds, truths = pred_distribution(har_model, test_dataset, device='cpu')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebdd34ac",
   "metadata": {},
   "source": [
    "**Confusion Matrix - Per Class Prediction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "edb7bd7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      " [[ 6  2  1  0  0  0  1  0  0  0  4  0  1  0  1]\n",
      " [ 2  4  1  1  3  1  2  1  0  0  1  0  0  0  0]\n",
      " [ 1  0  9  0  0  0  0  2  0  2  1  0  1  0  0]\n",
      " [ 1  1  0  7  0  1  3  0  0  1  1  0  1  0  0]\n",
      " [ 2  0  0  0  9  0  1  1  0  0  0  0  1  2  0]\n",
      " [ 0  0  0  0  1 10  1  0  1  2  0  0  0  0  1]\n",
      " [ 0  0  1  3  0  1  3  0  0  2  2  2  0  1  1]\n",
      " [ 2  0  1  0  0  0  0 10  2  0  0  0  0  0  1]\n",
      " [ 0  0  3  0  0  0  0  6  7  0  0  0  0  0  0]\n",
      " [ 0  2  1  1  0  0  1  1  0  4  3  0  1  0  2]\n",
      " [ 4  0  1  2  0  0  2  0  0  0  5  0  0  1  1]\n",
      " [ 1  0  3  3  2  0  0  0  1  0  1  3  1  0  1]\n",
      " [ 1  0  1  1  1  3  0  0  0  0  0  2  7  0  0]\n",
      " [ 1  0  0  0  4  2  1  0  0  0  0  1  0  7  0]\n",
      " [ 2  1  1  2  0  1  1  0  0  0  4  0  1  0  3]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.2609    0.3750    0.3077        16\n",
      "           1     0.4000    0.2500    0.3077        16\n",
      "           2     0.3913    0.5625    0.4615        16\n",
      "           3     0.3500    0.4375    0.3889        16\n",
      "           4     0.4500    0.5625    0.5000        16\n",
      "           5     0.5263    0.6250    0.5714        16\n",
      "           6     0.1875    0.1875    0.1875        16\n",
      "           7     0.4762    0.6250    0.5405        16\n",
      "           8     0.6364    0.4375    0.5185        16\n",
      "           9     0.3636    0.2500    0.2963        16\n",
      "          10     0.2273    0.3125    0.2632        16\n",
      "          11     0.3750    0.1875    0.2500        16\n",
      "          12     0.5000    0.4375    0.4667        16\n",
      "          13     0.6364    0.4375    0.5185        16\n",
      "          14     0.2727    0.1875    0.2222        16\n",
      "\n",
      "    accuracy                         0.3917       240\n",
      "   macro avg     0.4036    0.3917    0.3867       240\n",
      "weighted avg     0.4036    0.3917    0.3867       240\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "cm = confusion_matrix(truths, preds)\n",
    "print(\"Confusion matrix:\\n\", cm)\n",
    "print(classification_report(truths, preds, digits=4))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
