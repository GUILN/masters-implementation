{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1b2d9ef",
   "metadata": {},
   "source": [
    "# Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84a5065f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-20 22:18:50,913 - INFO - Sentry DSN set to: https://f4f21cc936b3ba9f5dbc1464b7a40ea4@o4504168838070272.ingest.us.sentry.io/4506464560414720\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading config...\n",
      "Loading secrets...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-20 22:18:50,914 - INFO - Sentry initialized with environment: development\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import sys\n",
    "sys.path.append(str(Path(os.getcwd()).parent))\n",
    "\n",
    "from settings.global_settings import GlobalSettings\n",
    "\n",
    "config = GlobalSettings.get_config(\n",
    "    config_file = \"../config.ini\",\n",
    "    secrets_file = \"../secrets.ini\"\n",
    ")\n",
    "from dataset.video_loader import VideoDataLoader\n",
    "from dataset.video_dataset import VideoDataset\n",
    "from model.training_loop import train\n",
    "from torch.utils.data import random_split\n",
    "from model.multimodal_har_model import MultiModalHARModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6cf9b62",
   "metadata": {},
   "source": [
    "## Initializing Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d691d46",
   "metadata": {},
   "source": [
    "**Creating Dataloaders**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d84473d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-20 22:18:53,220 - INFO - [VideoDataLoader] Loding action videos for action: a01\n",
      "2025-10-20 22:18:53,604 - INFO - [VideoDataLoader] Loding action videos for action: a02\n",
      "2025-10-20 22:18:54,031 - INFO - [VideoDataLoader] Loding action videos for action: a03\n",
      "2025-10-20 22:18:54,381 - INFO - [VideoDataLoader] Loding action videos for action: a04\n",
      "2025-10-20 22:18:54,892 - INFO - [VideoDataLoader] Loding action videos for action: a05\n",
      "2025-10-20 22:18:55,212 - INFO - [VideoDataLoader] Loding action videos for action: a06\n",
      "2025-10-20 22:18:55,631 - INFO - [VideoDataLoader] Loding action videos for action: a08\n",
      "2025-10-20 22:18:56,358 - INFO - [VideoDataLoader] Loding action videos for action: a09\n",
      "2025-10-20 22:18:57,235 - INFO - [VideoDataLoader] Loding action videos for action: a11\n",
      "2025-10-20 22:18:57,520 - INFO - [VideoDataLoader] Loding action videos for action: a12\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_data_loader = VideoDataLoader(\n",
    "    path=config.model_settings.video_data_dir\n",
    ")\n",
    "\n",
    "video_dataset = VideoDataset(\n",
    "    video_data_loader=video_data_loader,\n",
    "    normalization_type=\"across_frames\",\n",
    ")\n",
    "\n",
    "len(video_dataset)\n",
    "for _ in video_dataset:\n",
    "    pass\n",
    "len(video_dataset.labels_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde5336f",
   "metadata": {},
   "source": [
    "**Splitting Train and Test Datasets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0c82257",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_total = len(video_dataset)\n",
    "num_train = int(0.8 * num_total)\n",
    "num_test = num_total - num_train\n",
    "train_dataset, test_dataset = random_split(video_dataset, [num_train, num_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef613137",
   "metadata": {},
   "source": [
    "**Creating Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "781f5692",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "har_model = MultiModalHARModel(\n",
    "    obj_in=train_dataset[0].graphs_objects[0].x.shape[1],\n",
    "    joint_in=train_dataset[0].graphs_joints[0].x.shape[1],\n",
    "    gat_hidden=128,\n",
    "    gat_out=128,\n",
    "    temporal_hidden=128,\n",
    "    num_classes=len(video_dataset.labels_map), \n",
    "    dropout=0.5,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33cabcd9",
   "metadata": {},
   "source": [
    "## Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b4ad38",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-20 22:19:03,031 - INFO - Starting training loop...\n",
      "Epoch 1/25: 100%|██████████| 1180/1180 [06:38<00:00,  2.96it/s]\n",
      "2025-10-20 22:25:41,573 - INFO - Epoch 1/25, Loss: 2.0608\n",
      "Epoch 2/25: 100%|██████████| 1180/1180 [06:17<00:00,  3.13it/s]\n",
      "2025-10-20 22:31:58,635 - INFO - Epoch 2/25, Loss: 1.4806\n",
      "Epoch 3/25: 100%|██████████| 1180/1180 [06:22<00:00,  3.09it/s]\n",
      "2025-10-20 22:38:21,047 - INFO - Epoch 3/25, Loss: 1.2626\n",
      "Epoch 4/25: 100%|██████████| 1180/1180 [06:18<00:00,  3.12it/s]\n",
      "2025-10-20 22:44:39,729 - INFO - Epoch 4/25, Loss: 1.1304\n",
      "Epoch 5/25: 100%|██████████| 1180/1180 [21:10<00:00,  1.08s/it]  \n",
      "2025-10-20 23:05:50,509 - INFO - Epoch 5/25, Loss: 1.0244\n",
      "Epoch 6/25: 100%|██████████| 1180/1180 [06:00<00:00,  3.27it/s]\n",
      "2025-10-20 23:11:50,956 - INFO - Epoch 6/25, Loss: 0.9403\n",
      "Epoch 7/25: 100%|██████████| 1180/1180 [06:00<00:00,  3.27it/s]\n",
      "2025-10-20 23:17:51,370 - INFO - Epoch 7/25, Loss: 0.8586\n",
      "Epoch 8/25: 100%|██████████| 1180/1180 [05:51<00:00,  3.35it/s]\n",
      "2025-10-20 23:23:43,279 - INFO - Epoch 8/25, Loss: 0.7807\n",
      "Epoch 9/25: 100%|██████████| 1180/1180 [05:57<00:00,  3.30it/s]\n",
      "2025-10-20 23:29:40,718 - INFO - Epoch 9/25, Loss: 0.7292\n",
      "Epoch 10/25: 100%|██████████| 1180/1180 [06:02<00:00,  3.26it/s]\n",
      "2025-10-20 23:35:43,200 - INFO - Epoch 10/25, Loss: 0.6924\n",
      "Epoch 11/25: 100%|██████████| 1180/1180 [05:59<00:00,  3.29it/s]\n",
      "2025-10-20 23:41:42,209 - INFO - Epoch 11/25, Loss: 0.6071\n",
      "Epoch 12/25: 100%|██████████| 1180/1180 [06:00<00:00,  3.27it/s]\n",
      "2025-10-20 23:47:42,651 - INFO - Epoch 12/25, Loss: 0.6598\n",
      "Epoch 13/25: 100%|██████████| 1180/1180 [05:59<00:00,  3.28it/s]\n",
      "2025-10-20 23:53:42,517 - INFO - Epoch 13/25, Loss: 0.5081\n",
      "Epoch 14/25: 100%|██████████| 1180/1180 [05:56<00:00,  3.31it/s]\n",
      "2025-10-20 23:59:39,193 - INFO - Epoch 14/25, Loss: 0.5428\n",
      "Epoch 15/25: 100%|██████████| 1180/1180 [05:56<00:00,  3.31it/s]\n",
      "2025-10-21 00:05:36,115 - INFO - Epoch 15/25, Loss: 0.4535\n",
      "Epoch 16/25: 100%|██████████| 1180/1180 [05:59<00:00,  3.28it/s]\n",
      "2025-10-21 00:11:35,619 - INFO - Epoch 16/25, Loss: 0.4284\n",
      "Epoch 17/25: 100%|██████████| 1180/1180 [06:27<00:00,  3.04it/s]\n",
      "2025-10-21 00:18:03,371 - INFO - Epoch 17/25, Loss: 0.4128\n",
      "Epoch 18/25: 100%|██████████| 1180/1180 [1:01:33<00:00,  3.13s/it]   \n",
      "2025-10-21 01:19:36,729 - INFO - Epoch 18/25, Loss: 0.3649\n",
      "Epoch 19/25: 100%|██████████| 1180/1180 [3:16:45<00:00, 10.01s/it]   \n",
      "2025-10-21 04:36:22,707 - INFO - Epoch 19/25, Loss: 0.3477\n",
      "Epoch 20/25: 100%|██████████| 1180/1180 [3:03:41<00:00,  9.34s/it]   \n",
      "2025-10-21 07:40:03,822 - INFO - Epoch 20/25, Loss: 0.3368\n",
      "Epoch 21/25: 100%|██████████| 1180/1180 [08:32<00:00,  2.30it/s]\n",
      "2025-10-21 07:48:36,024 - INFO - Epoch 21/25, Loss: 0.3593\n",
      "Epoch 22/25: 100%|██████████| 1180/1180 [06:18<00:00,  3.12it/s]\n",
      "2025-10-21 07:54:54,043 - INFO - Epoch 22/25, Loss: 0.3026\n",
      "Epoch 23/25: 100%|██████████| 1180/1180 [06:17<00:00,  3.12it/s]\n",
      "2025-10-21 08:01:11,816 - INFO - Epoch 23/25, Loss: 0.3291\n",
      "Epoch 24/25: 100%|██████████| 1180/1180 [06:15<00:00,  3.14it/s]\n",
      "2025-10-21 08:07:27,406 - INFO - Epoch 24/25, Loss: 0.2949\n",
      "Epoch 25/25: 100%|██████████| 1180/1180 [06:24<00:00,  3.07it/s]\n",
      "2025-10-21 08:13:52,339 - INFO - Epoch 25/25, Loss: 0.2696\n"
     ]
    }
   ],
   "source": [
    "train_history = train(\n",
    "    model=har_model,\n",
    "    video_dataset=train_dataset,\n",
    "    device='mps',\n",
    "    epochs=25,\n",
    "    weight_decay=1e-4,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd5bc8d",
   "metadata": {},
   "source": [
    "**Saving Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66b74bb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-21 08:13:52,393 - INFO - Saving model to /Volumes/KODAK/masters/model/validation_datasets/NW-UCLA/model/har_model_v0.0.0_nw_ucla_2025-10-21 08:13:52.392482.pht...\n",
      "2025-10-21 08:13:52,576 - INFO - Model saved successfully.\n"
     ]
    }
   ],
   "source": [
    "har_model.save(\n",
    "    training_history=train_history\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d02e53d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test video IDs: [64, 798, 128, 959, 1158, 1205, 1453, 53, 915, 762, 578, 1130, 1006, 73, 1287, 690, 1171, 810, 27, 748, 809, 183, 407, 444, 540, 976, 919, 1111, 1340, 84, 576, 606, 228, 287, 1013, 336, 431, 1462, 372, 1368, 1378, 202, 884, 855, 509, 1337, 549, 590, 369, 226, 243, 1132, 984, 538, 14, 756, 1243, 113, 317, 735, 531, 613, 16, 787, 541, 956, 903, 1225, 642, 1406, 1230, 667, 358, 664, 1365, 120, 1272, 605, 199, 559, 342, 1066, 1157, 791, 1294, 1041, 246, 302, 661, 722, 927, 295, 1057, 1242, 1219, 0, 633, 515, 871, 713, 691, 1256, 121, 1460, 867, 947, 33, 921, 673, 944, 175, 245, 930, 1367, 676, 624, 1457, 1316, 556, 1304, 318, 693, 1134, 1353, 255, 1226, 1089, 768, 726, 939, 297, 326, 496, 1428, 627, 694, 347, 276, 176, 1321, 1466, 914, 153, 1113, 385, 542, 799, 2, 614, 329, 1103, 835, 331, 880, 1383, 351, 205, 118, 1016, 983, 1330, 675, 934, 696, 507, 1400, 648, 380, 1300, 926, 341, 1357, 343, 1098, 1380, 100, 961, 210, 437, 831, 843, 641, 901, 719, 31, 981, 895, 187, 596, 216, 1245, 490, 294, 861, 1068, 230, 466, 510, 96, 1033, 106, 517, 151, 101, 197, 528, 546, 600, 1298, 712, 1371, 1354, 432, 656, 1235, 1241, 1063, 770, 980, 977, 1153, 1402, 502, 842, 830, 1020, 291, 78, 41, 992, 1110, 818, 963, 411, 39, 1167, 1228, 829, 941, 463, 1465, 1452, 471, 1017, 69, 233, 1159, 92, 504, 1213, 324, 1117, 1139, 786, 212, 785, 609, 1467, 201, 68, 72, 862, 497, 1408, 1261, 1386, 906, 870, 1122, 1425, 461, 484, 728, 303, 1251, 689, 586, 682, 451, 442, 262, 254, 814, 1290, 237, 1288, 124, 1312, 796, 12, 1385, 63, 217, 1081, 264]\n"
     ]
    }
   ],
   "source": [
    "test_video_indices = test_dataset.indices\n",
    "print(\"Test video IDs:\", test_video_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4056878c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from datetime import datetime\n",
    "\n",
    "model_settings = config.model_settings\n",
    "save_dir = \"~/masters-models\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "save_path = os.path.join(\n",
    "    save_dir,\n",
    "    f\"har_model_{model_settings.model_version}_{model_settings.dataset_prefix}_100perc_{datetime.now()}.pht\"\n",
    ")\n",
    "torch.save({\n",
    "\"model_state_dict\": har_model.state_dict(),\n",
    "\"training_history\": train_history,\n",
    "\"model_config\": har_model._model_config,\n",
    "\"test_set_indices\": test_video_indices,\n",
    "}, save_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8bf73a0",
   "metadata": {},
   "source": [
    "## Running tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe0f60c1",
   "metadata": {},
   "source": [
    "**Accuracy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a215b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, dataset, device):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i in range(len(dataset)):\n",
    "            sample = dataset[i]\n",
    "            label = sample.label.to(device)\n",
    "\n",
    "            # Move all graph tensors to device\n",
    "            graphs_objects = [g.to(device) for g in sample.graphs_objects]\n",
    "            graphs_joints = [g.to(device) for g in sample.graphs_joints]\n",
    "\n",
    "            # Forward pass\n",
    "            output = model(graphs_objects, graphs_joints)\n",
    "\n",
    "            # Compute prediction\n",
    "            if output.dim() == 1:\n",
    "                predicted = torch.argmax(output).unsqueeze(0)\n",
    "            else:\n",
    "                _, predicted = torch.max(output, dim=1)\n",
    "\n",
    "            correct += (predicted == label).sum().item()\n",
    "            total += 1\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a102aee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 58.64%\n"
     ]
    }
   ],
   "source": [
    "accuracy_evaluation = evaluate(har_model, test_dataset, \"mps\")\n",
    "print(f\"Test Accuracy: {accuracy_evaluation:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
