{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1b2d9ef",
   "metadata": {},
   "source": [
    "# Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84a5065f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-20 10:25:53,563 - INFO - Sentry DSN set to: https://f4f21cc936b3ba9f5dbc1464b7a40ea4@o4504168838070272.ingest.us.sentry.io/4506464560414720\n",
      "2025-10-20 10:25:53,564 - INFO - Sentry initialized with environment: development\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading config...\n",
      "Loading secrets...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import sys\n",
    "sys.path.append(str(Path(os.getcwd()).parent))\n",
    "\n",
    "from settings.global_settings import GlobalSettings\n",
    "\n",
    "config = GlobalSettings.get_config(\n",
    "    config_file = \"../config.ini\",\n",
    "    secrets_file = \"../secrets.ini\"\n",
    ")\n",
    "from dataset.video_loader import VideoDataLoader\n",
    "from dataset.video_dataset import VideoDataset\n",
    "from model.training_loop import train\n",
    "from torch.utils.data import random_split\n",
    "from model.multimodal_har_model import MultiModalHARModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6cf9b62",
   "metadata": {},
   "source": [
    "## Initializing Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d691d46",
   "metadata": {},
   "source": [
    "**Creating Dataloaders**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d84473d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-20 10:25:55,288 - INFO - [VideoDataLoader] Loding action videos for action: a01\n",
      "2025-10-20 10:25:55,612 - INFO - [VideoDataLoader] Loding action videos for action: a02\n",
      "2025-10-20 10:25:55,970 - INFO - [VideoDataLoader] Loding action videos for action: a03\n",
      "2025-10-20 10:25:56,216 - INFO - [VideoDataLoader] Loding action videos for action: a04\n",
      "2025-10-20 10:25:56,642 - INFO - [VideoDataLoader] Loding action videos for action: a05\n",
      "2025-10-20 10:25:57,128 - INFO - [VideoDataLoader] Loding action videos for action: a06\n",
      "2025-10-20 10:25:57,466 - INFO - [VideoDataLoader] Loding action videos for action: a08\n",
      "2025-10-20 10:25:58,159 - INFO - [VideoDataLoader] Loding action videos for action: a09\n",
      "2025-10-20 10:25:58,761 - INFO - [VideoDataLoader] Loding action videos for action: a11\n",
      "2025-10-20 10:25:58,993 - INFO - [VideoDataLoader] Loding action videos for action: a12\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_data_loader = VideoDataLoader(\n",
    "    path=config.model_settings.video_data_dir\n",
    ")\n",
    "\n",
    "video_dataset = VideoDataset(\n",
    "    video_data_loader=video_data_loader,\n",
    "    normalization_type=\"across_frames\",\n",
    ")\n",
    "\n",
    "len(video_dataset)\n",
    "for _ in video_dataset:\n",
    "    pass\n",
    "len(video_dataset.labels_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde5336f",
   "metadata": {},
   "source": [
    "**Splitting Train and Test Datasets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0c82257",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_total = len(video_dataset)\n",
    "num_train = int(0.8 * num_total)\n",
    "num_test = num_total - num_train\n",
    "train_dataset, test_dataset = random_split(video_dataset, [num_train, num_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef613137",
   "metadata": {},
   "source": [
    "**Creating Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "781f5692",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "har_model = MultiModalHARModel(\n",
    "    obj_in=train_dataset[0].graphs_objects[0].x.shape[1],\n",
    "    joint_in=train_dataset[0].graphs_joints[0].x.shape[1],\n",
    "    gat_hidden=128,\n",
    "    gat_out=128,\n",
    "    temporal_hidden=128,\n",
    "    num_classes=len(video_dataset.labels_map), \n",
    "    dropout=0.5,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33cabcd9",
   "metadata": {},
   "source": [
    "## Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37b4ad38",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-20 10:26:04,440 - INFO - Starting training loop...\n",
      "Epoch 1/25: 100%|██████████| 1180/1180 [06:20<00:00,  3.10it/s]\n",
      "2025-10-20 10:32:24,781 - INFO - Epoch 1/25, Loss: 2.0124\n",
      "Epoch 2/25: 100%|██████████| 1180/1180 [06:07<00:00,  3.21it/s]\n",
      "2025-10-20 10:38:31,830 - INFO - Epoch 2/25, Loss: 1.3966\n",
      "Epoch 3/25: 100%|██████████| 1180/1180 [06:07<00:00,  3.21it/s]\n",
      "2025-10-20 10:44:38,884 - INFO - Epoch 3/25, Loss: 1.0965\n",
      "Epoch 4/25: 100%|██████████| 1180/1180 [06:09<00:00,  3.20it/s]\n",
      "2025-10-20 10:50:47,955 - INFO - Epoch 4/25, Loss: 0.9716\n",
      "Epoch 5/25: 100%|██████████| 1180/1180 [06:08<00:00,  3.20it/s]\n",
      "2025-10-20 10:56:56,270 - INFO - Epoch 5/25, Loss: 0.8799\n",
      "Epoch 6/25: 100%|██████████| 1180/1180 [06:14<00:00,  3.15it/s]\n",
      "2025-10-20 11:03:10,654 - INFO - Epoch 6/25, Loss: 0.8144\n",
      "Epoch 7/25: 100%|██████████| 1180/1180 [06:09<00:00,  3.20it/s]\n",
      "2025-10-20 11:09:19,835 - INFO - Epoch 7/25, Loss: 0.7349\n",
      "Epoch 8/25: 100%|██████████| 1180/1180 [06:08<00:00,  3.20it/s]\n",
      "2025-10-20 11:15:28,529 - INFO - Epoch 8/25, Loss: 0.6814\n",
      "Epoch 9/25: 100%|██████████| 1180/1180 [06:10<00:00,  3.19it/s]\n",
      "2025-10-20 11:21:38,918 - INFO - Epoch 9/25, Loss: 0.6651\n",
      "Epoch 10/25: 100%|██████████| 1180/1180 [06:13<00:00,  3.16it/s]\n",
      "2025-10-20 11:27:52,821 - INFO - Epoch 10/25, Loss: 0.6582\n",
      "Epoch 11/25: 100%|██████████| 1180/1180 [06:15<00:00,  3.14it/s]\n",
      "2025-10-20 11:34:08,443 - INFO - Epoch 11/25, Loss: 0.5507\n",
      "Epoch 12/25: 100%|██████████| 1180/1180 [06:05<00:00,  3.23it/s]\n",
      "2025-10-20 11:40:13,757 - INFO - Epoch 12/25, Loss: 0.5011\n",
      "Epoch 13/25: 100%|██████████| 1180/1180 [06:03<00:00,  3.24it/s]\n",
      "2025-10-20 11:46:17,681 - INFO - Epoch 13/25, Loss: 0.4606\n",
      "Epoch 14/25: 100%|██████████| 1180/1180 [08:01<00:00,  2.45it/s] \n",
      "2025-10-20 11:54:19,433 - INFO - Epoch 14/25, Loss: 0.5027\n",
      "Epoch 15/25: 100%|██████████| 1180/1180 [06:17<00:00,  3.13it/s]\n",
      "2025-10-20 12:00:36,960 - INFO - Epoch 15/25, Loss: 0.4060\n",
      "Epoch 16/25: 100%|██████████| 1180/1180 [06:22<00:00,  3.08it/s]\n",
      "2025-10-20 12:06:59,482 - INFO - Epoch 16/25, Loss: 0.4156\n",
      "Epoch 17/25: 100%|██████████| 1180/1180 [06:17<00:00,  3.12it/s]\n",
      "2025-10-20 12:13:17,194 - INFO - Epoch 17/25, Loss: 0.4178\n",
      "Epoch 18/25: 100%|██████████| 1180/1180 [06:18<00:00,  3.12it/s]\n",
      "2025-10-20 12:19:35,461 - INFO - Epoch 18/25, Loss: 0.3138\n",
      "Epoch 19/25: 100%|██████████| 1180/1180 [06:16<00:00,  3.14it/s]\n",
      "2025-10-20 12:25:51,756 - INFO - Epoch 19/25, Loss: 0.3672\n",
      "Epoch 20/25: 100%|██████████| 1180/1180 [06:18<00:00,  3.12it/s]\n",
      "2025-10-20 12:32:10,368 - INFO - Epoch 20/25, Loss: 0.2744\n",
      "Epoch 21/25: 100%|██████████| 1180/1180 [06:20<00:00,  3.10it/s]\n",
      "2025-10-20 12:38:30,621 - INFO - Epoch 21/25, Loss: 0.3460\n",
      "Epoch 22/25: 100%|██████████| 1180/1180 [06:20<00:00,  3.10it/s]\n",
      "2025-10-20 12:44:51,257 - INFO - Epoch 22/25, Loss: 0.2402\n",
      "Epoch 23/25: 100%|██████████| 1180/1180 [06:14<00:00,  3.15it/s]\n",
      "2025-10-20 12:51:05,875 - INFO - Epoch 23/25, Loss: 0.2833\n",
      "Epoch 24/25: 100%|██████████| 1180/1180 [06:16<00:00,  3.14it/s]\n",
      "2025-10-20 12:57:21,972 - INFO - Epoch 24/25, Loss: 0.3209\n",
      "Epoch 25/25: 100%|██████████| 1180/1180 [06:46<00:00,  2.90it/s]\n",
      "2025-10-20 13:04:08,889 - INFO - Epoch 25/25, Loss: 0.2661\n"
     ]
    }
   ],
   "source": [
    "train_history = train(\n",
    "    model=har_model,\n",
    "    video_dataset=train_dataset,\n",
    "    device='mps',\n",
    "    epochs=25,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd5bc8d",
   "metadata": {},
   "source": [
    "**Saving Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66b74bb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-20 13:04:09,168 - INFO - Saving model to /Volumes/KODAK/masters/model/validation_datasets/NW-UCLA/model/har_model_v0.0.0_nw_ucla_2025-10-20 13:04:09.166170.pht...\n",
      "2025-10-20 13:04:09,352 - INFO - Model saved successfully.\n"
     ]
    }
   ],
   "source": [
    "har_model.save(\n",
    "    training_history=train_history\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d02e53d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test video IDs: [6, 1012, 401, 306, 246, 301, 853, 1106, 194, 113, 599, 1438, 138, 1318, 423, 422, 338, 639, 765, 922, 1322, 304, 379, 1380, 319, 1429, 1098, 1185, 1154, 905, 159, 1445, 993, 419, 45, 322, 1426, 830, 1138, 767, 1285, 184, 449, 728, 938, 368, 697, 281, 1284, 1189, 1104, 314, 1259, 160, 1025, 1312, 1363, 1466, 458, 877, 93, 456, 34, 1294, 466, 638, 390, 400, 1046, 1348, 230, 953, 809, 642, 706, 886, 1417, 975, 806, 1136, 154, 546, 766, 1395, 776, 1033, 841, 1151, 1183, 1276, 1323, 937, 569, 276, 217, 1082, 995, 557, 1017, 1112, 994, 876, 1239, 1415, 907, 356, 441, 66, 1263, 884, 343, 1393, 515, 64, 158, 420, 127, 0, 1308, 1277, 935, 416, 87, 185, 227, 942, 308, 1178, 926, 397, 122, 1462, 79, 1044, 1014, 636, 470, 1399, 1093, 1186, 1134, 606, 142, 210, 398, 947, 669, 843, 1193, 524, 335, 793, 1152, 403, 990, 825, 717, 597, 751, 1262, 39, 90, 378, 448, 225, 603, 883, 1019, 1188, 970, 1304, 665, 1147, 1076, 514, 564, 572, 959, 18, 58, 490, 1269, 1260, 1329, 346, 199, 949, 592, 769, 83, 1224, 576, 121, 763, 1141, 1206, 1358, 689, 846, 593, 507, 1232, 596, 839, 803, 1368, 684, 104, 758, 149, 532, 1026, 722, 1050, 52, 1103, 1015, 305, 761, 1425, 30, 1153, 762, 1009, 108, 1205, 696, 802, 1453, 1077, 588, 344, 1102, 101, 377, 1003, 923, 622, 1472, 673, 426, 797, 15, 289, 871, 489, 607, 980, 974, 220, 176, 1007, 442, 887, 109, 1458, 770, 1403, 56, 516, 1045, 738, 326, 784, 1204, 1306, 1024, 647, 221, 944, 309, 1042, 428, 932, 1352, 620, 444, 1321, 1094, 896, 287, 1171, 349, 144, 285, 1080, 171, 798, 702, 1108, 62, 1409, 46, 865, 80]\n"
     ]
    }
   ],
   "source": [
    "test_video_indices = test_dataset.indices\n",
    "print(\"Test video IDs:\", test_video_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4056878c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from datetime import datetime\n",
    "\n",
    "model_settings = config.model_settings\n",
    "save_dir = \"~/masters-models\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "save_path = os.path.join(\n",
    "    save_dir,\n",
    "    f\"har_model_{model_settings.model_version}_{model_settings.dataset_prefix}_100perc_{datetime.now()}.pht\"\n",
    ")\n",
    "torch.save({\n",
    "\"model_state_dict\": har_model.state_dict(),\n",
    "\"training_history\": train_history,\n",
    "\"model_config\": har_model._model_config,\n",
    "\"test_set_indices\": test_video_indices,\n",
    "}, save_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8bf73a0",
   "metadata": {},
   "source": [
    "## Running tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe0f60c1",
   "metadata": {},
   "source": [
    "**Accuracy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a215b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, dataset, device):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i in range(len(dataset)):\n",
    "            sample = dataset[i]\n",
    "            label = sample.label.to(device)\n",
    "\n",
    "            # Move all graph tensors to device\n",
    "            graphs_objects = [g.to(device) for g in sample.graphs_objects]\n",
    "            graphs_joints = [g.to(device) for g in sample.graphs_joints]\n",
    "\n",
    "            # Forward pass\n",
    "            output = model(graphs_objects, graphs_joints)\n",
    "\n",
    "            # Compute prediction\n",
    "            if output.dim() == 1:\n",
    "                predicted = torch.argmax(output).unsqueeze(0)\n",
    "            else:\n",
    "                _, predicted = torch.max(output, dim=1)\n",
    "\n",
    "            correct += (predicted == label).sum().item()\n",
    "            total += 1\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a102aee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 63.73%\n"
     ]
    }
   ],
   "source": [
    "accuracy_evaluation = evaluate(har_model, test_dataset, \"mps\")\n",
    "print(f\"Test Accuracy: {accuracy_evaluation:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
