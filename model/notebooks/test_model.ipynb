{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1b2d9ef",
   "metadata": {},
   "source": [
    "# Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84a5065f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-19 22:26:10,861 - INFO - Sentry DSN set to: https://f4f21cc936b3ba9f5dbc1464b7a40ea4@o4504168838070272.ingest.us.sentry.io/4506464560414720\n",
      "2025-10-19 22:26:10,862 - INFO - Sentry initialized with environment: development\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading config...\n",
      "Loading secrets...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import sys\n",
    "sys.path.append(str(Path(os.getcwd()).parent))\n",
    "\n",
    "from settings.global_settings import GlobalSettings\n",
    "\n",
    "config = GlobalSettings.get_config(\n",
    "    config_file = \"../config.ini\",\n",
    "    secrets_file = \"../secrets.ini\"\n",
    ")\n",
    "from dataset.video_loader import VideoDataLoader\n",
    "from dataset.video_dataset import VideoDataset\n",
    "from model.training_loop import train\n",
    "from torch.utils.data import random_split\n",
    "from model.multimodal_har_model import MultiModalHARModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6cf9b62",
   "metadata": {},
   "source": [
    "## Initializing Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d691d46",
   "metadata": {},
   "source": [
    "**Creating Dataloaders**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d84473d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-19 22:26:12,727 - INFO - [VideoDataLoader] Loding action videos for action: a01\n",
      "2025-10-19 22:26:13,199 - INFO - [VideoDataLoader] Loding action videos for action: a02\n",
      "2025-10-19 22:26:13,667 - INFO - [VideoDataLoader] Loding action videos for action: a03\n",
      "2025-10-19 22:26:14,171 - INFO - [VideoDataLoader] Loding action videos for action: a04\n",
      "2025-10-19 22:26:14,792 - INFO - [VideoDataLoader] Loding action videos for action: a05\n",
      "2025-10-19 22:26:15,097 - INFO - [VideoDataLoader] Loding action videos for action: a06\n",
      "2025-10-19 22:26:15,589 - INFO - [VideoDataLoader] Loding action videos for action: a08\n",
      "2025-10-19 22:26:16,769 - INFO - [VideoDataLoader] Loding action videos for action: a09\n",
      "2025-10-19 22:26:17,595 - INFO - [VideoDataLoader] Loding action videos for action: a11\n",
      "2025-10-19 22:26:17,953 - INFO - [VideoDataLoader] Loding action videos for action: a12\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_data_loader = VideoDataLoader(\n",
    "    path=config.model_settings.video_data_dir\n",
    ")\n",
    "\n",
    "video_dataset = VideoDataset(\n",
    "    video_data_loader=video_data_loader,\n",
    "    normalization_type=\"across_frames\",\n",
    ")\n",
    "\n",
    "len(video_dataset)\n",
    "for _ in video_dataset:\n",
    "    pass\n",
    "len(video_dataset.labels_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde5336f",
   "metadata": {},
   "source": [
    "**Splitting Train and Test Datasets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0c82257",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_total = len(video_dataset)\n",
    "num_train = int(0.8 * num_total)\n",
    "num_test = num_total - num_train\n",
    "train_dataset, test_dataset = random_split(video_dataset, [num_train, num_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef613137",
   "metadata": {},
   "source": [
    "**Creating Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "781f5692",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "har_model = MultiModalHARModel(\n",
    "    obj_in=train_dataset[0].graphs_objects[0].x.shape[1],\n",
    "    joint_in=train_dataset[0].graphs_joints[0].x.shape[1],\n",
    "    gat_hidden=128,\n",
    "    gat_out=128,\n",
    "    temporal_hidden=128,\n",
    "    num_classes=len(video_dataset.labels_map), \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33cabcd9",
   "metadata": {},
   "source": [
    "## Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37b4ad38",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-19 22:26:23,390 - INFO - Starting training loop...\n",
      "Epoch 1/25: 100%|██████████| 1180/1180 [06:02<00:00,  3.25it/s]\n",
      "2025-10-19 22:32:26,279 - INFO - Epoch 1/25, Loss: 2.0920\n",
      "Epoch 2/25: 100%|██████████| 1180/1180 [07:06<00:00,  2.77it/s]\n",
      "2025-10-19 22:39:32,519 - INFO - Epoch 2/25, Loss: 1.6218\n",
      "Epoch 3/25: 100%|██████████| 1180/1180 [05:53<00:00,  3.33it/s]\n",
      "2025-10-19 22:45:26,389 - INFO - Epoch 3/25, Loss: 1.2853\n",
      "Epoch 4/25: 100%|██████████| 1180/1180 [05:50<00:00,  3.36it/s]\n",
      "2025-10-19 22:51:17,319 - INFO - Epoch 4/25, Loss: 1.0693\n",
      "Epoch 5/25: 100%|██████████| 1180/1180 [08:19<00:00,  2.36it/s]\n",
      "2025-10-19 22:59:36,453 - INFO - Epoch 5/25, Loss: 0.9750\n",
      "Epoch 6/25: 100%|██████████| 1180/1180 [05:55<00:00,  3.32it/s]\n",
      "2025-10-19 23:05:31,833 - INFO - Epoch 6/25, Loss: 0.9366\n",
      "Epoch 7/25: 100%|██████████| 1180/1180 [06:55<00:00,  2.84it/s]\n",
      "2025-10-19 23:12:27,409 - INFO - Epoch 7/25, Loss: 0.8637\n",
      "Epoch 8/25: 100%|██████████| 1180/1180 [21:17<00:00,  1.08s/it]   \n",
      "2025-10-19 23:33:45,264 - INFO - Epoch 8/25, Loss: 0.7507\n",
      "Epoch 9/25: 100%|██████████| 1180/1180 [05:35<00:00,  3.52it/s]\n",
      "2025-10-19 23:39:20,511 - INFO - Epoch 9/25, Loss: 0.7080\n",
      "Epoch 10/25: 100%|██████████| 1180/1180 [05:54<00:00,  3.33it/s]\n",
      "2025-10-19 23:45:14,824 - INFO - Epoch 10/25, Loss: 0.6563\n",
      "Epoch 11/25: 100%|██████████| 1180/1180 [17:21<00:00,  1.13it/s] \n",
      "2025-10-20 00:02:36,806 - INFO - Epoch 11/25, Loss: 0.5703\n",
      "Epoch 12/25: 100%|██████████| 1180/1180 [05:55<00:00,  3.32it/s]\n",
      "2025-10-20 00:08:32,629 - INFO - Epoch 12/25, Loss: 0.5301\n",
      "Epoch 13/25: 100%|██████████| 1180/1180 [21:23<00:00,  1.09s/it]    \n",
      "2025-10-20 00:29:56,197 - INFO - Epoch 13/25, Loss: 0.4254\n",
      "Epoch 14/25: 100%|██████████| 1180/1180 [05:37<00:00,  3.50it/s]\n",
      "2025-10-20 00:35:33,215 - INFO - Epoch 14/25, Loss: 0.4362\n",
      "Epoch 15/25: 100%|██████████| 1180/1180 [06:54<00:00,  2.85it/s]\n",
      "2025-10-20 00:42:27,365 - INFO - Epoch 15/25, Loss: 0.3648\n",
      "Epoch 16/25: 100%|██████████| 1180/1180 [05:41<00:00,  3.46it/s]\n",
      "2025-10-20 00:48:08,798 - INFO - Epoch 16/25, Loss: 0.3108\n",
      "Epoch 17/25: 100%|██████████| 1180/1180 [05:37<00:00,  3.50it/s]\n",
      "2025-10-20 00:53:45,974 - INFO - Epoch 17/25, Loss: 0.3784\n",
      "Epoch 18/25: 100%|██████████| 1180/1180 [11:05<00:00,  1.77it/s]  \n",
      "2025-10-20 01:04:51,705 - INFO - Epoch 18/25, Loss: 0.2179\n",
      "Epoch 19/25: 100%|██████████| 1180/1180 [05:38<00:00,  3.48it/s]\n",
      "2025-10-20 01:10:30,321 - INFO - Epoch 19/25, Loss: 0.2250\n",
      "Epoch 20/25: 100%|██████████| 1180/1180 [05:33<00:00,  3.53it/s]\n",
      "2025-10-20 01:16:04,262 - INFO - Epoch 20/25, Loss: 0.3546\n",
      "Epoch 21/25: 100%|██████████| 1180/1180 [05:36<00:00,  3.50it/s]\n",
      "2025-10-20 01:21:41,012 - INFO - Epoch 21/25, Loss: 0.2266\n",
      "Epoch 22/25: 100%|██████████| 1180/1180 [08:55<00:00,  2.20it/s] \n",
      "2025-10-20 01:30:36,212 - INFO - Epoch 22/25, Loss: 0.1477\n",
      "Epoch 23/25: 100%|██████████| 1180/1180 [05:42<00:00,  3.44it/s]\n",
      "2025-10-20 01:36:18,911 - INFO - Epoch 23/25, Loss: 0.1633\n",
      "Epoch 24/25: 100%|██████████| 1180/1180 [05:48<00:00,  3.39it/s]\n",
      "2025-10-20 01:42:06,931 - INFO - Epoch 24/25, Loss: 0.1309\n",
      "Epoch 25/25: 100%|██████████| 1180/1180 [05:50<00:00,  3.37it/s]\n",
      "2025-10-20 01:47:57,310 - INFO - Epoch 25/25, Loss: 0.1653\n"
     ]
    }
   ],
   "source": [
    "train_history = train(\n",
    "    model=har_model,\n",
    "    video_dataset=train_dataset,\n",
    "    device='mps',\n",
    "    epochs=25,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd5bc8d",
   "metadata": {},
   "source": [
    "**Saving Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "66b74bb1",
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: '/Volumes/KODAK'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mhar_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtraining_history\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_history\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/temp/masters-implementation/model/model/multimodal_har_model.py:73\u001b[0m, in \u001b[0;36mMultiModalHARModel.save\u001b[0;34m(self, training_history)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21msave\u001b[39m(\u001b[38;5;28mself\u001b[39m, training_history: Optional[Any]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     model_settings \u001b[38;5;241m=\u001b[39m GlobalSettings\u001b[38;5;241m.\u001b[39mget_config()\u001b[38;5;241m.\u001b[39mmodel_settings\n\u001b[0;32m---> 73\u001b[0m     \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmakedirs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_settings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_save_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexist_ok\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m     save_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\n\u001b[1;32m     76\u001b[0m         model_settings\u001b[38;5;241m.\u001b[39mmodel_save_dir,\n\u001b[1;32m     77\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhar_model_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_settings\u001b[38;5;241m.\u001b[39mmodel_version\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_settings\u001b[38;5;241m.\u001b[39mdataset_prefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdatetime\u001b[38;5;241m.\u001b[39mnow()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pht\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     78\u001b[0m     )\n\u001b[1;32m     79\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSaving model to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msave_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.16/lib/python3.9/os.py:215\u001b[0m, in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m head \u001b[38;5;129;01mand\u001b[39;00m tail \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m path\u001b[38;5;241m.\u001b[39mexists(head):\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 215\u001b[0m         \u001b[43mmakedirs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhead\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexist_ok\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexist_ok\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileExistsError\u001b[39;00m:\n\u001b[1;32m    217\u001b[0m         \u001b[38;5;66;03m# Defeats race condition when another thread created the path\u001b[39;00m\n\u001b[1;32m    218\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.16/lib/python3.9/os.py:215\u001b[0m, in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m head \u001b[38;5;129;01mand\u001b[39;00m tail \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m path\u001b[38;5;241m.\u001b[39mexists(head):\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 215\u001b[0m         \u001b[43mmakedirs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhead\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexist_ok\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexist_ok\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileExistsError\u001b[39;00m:\n\u001b[1;32m    217\u001b[0m         \u001b[38;5;66;03m# Defeats race condition when another thread created the path\u001b[39;00m\n\u001b[1;32m    218\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "    \u001b[0;31m[... skipping similar frames: makedirs at line 215 (2 times)]\u001b[0m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.16/lib/python3.9/os.py:215\u001b[0m, in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m head \u001b[38;5;129;01mand\u001b[39;00m tail \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m path\u001b[38;5;241m.\u001b[39mexists(head):\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 215\u001b[0m         \u001b[43mmakedirs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhead\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexist_ok\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexist_ok\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileExistsError\u001b[39;00m:\n\u001b[1;32m    217\u001b[0m         \u001b[38;5;66;03m# Defeats race condition when another thread created the path\u001b[39;00m\n\u001b[1;32m    218\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.16/lib/python3.9/os.py:225\u001b[0m, in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 225\u001b[0m     \u001b[43mmkdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[1;32m    227\u001b[0m     \u001b[38;5;66;03m# Cannot rely on checking for EEXIST, since the operating system\u001b[39;00m\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;66;03m# could give priority to other errors like EACCES or EROFS\u001b[39;00m\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m exist_ok \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m path\u001b[38;5;241m.\u001b[39misdir(name):\n",
      "\u001b[0;31mPermissionError\u001b[0m: [Errno 13] Permission denied: '/Volumes/KODAK'"
     ]
    }
   ],
   "source": [
    "har_model.save(\n",
    "    training_history=train_history\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3d02e53d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test video IDs: [577, 711, 1456, 507, 730, 1338, 1391, 1231, 82, 936, 1109, 828, 1085, 320, 34, 928, 894, 1459, 1092, 681, 195, 874, 790, 947, 582, 1469, 1050, 1197, 788, 597, 651, 906, 429, 288, 870, 69, 913, 1218, 1467, 377, 1196, 306, 345, 1246, 2, 1323, 735, 25, 1033, 223, 1157, 1052, 756, 1139, 41, 1156, 548, 90, 245, 233, 30, 1006, 485, 129, 1321, 197, 274, 1272, 32, 295, 591, 601, 277, 558, 1160, 198, 360, 1145, 24, 823, 701, 87, 391, 381, 1305, 1453, 143, 879, 852, 643, 1229, 1161, 83, 1055, 176, 1174, 1443, 1306, 204, 476, 1214, 467, 141, 665, 555, 666, 1049, 934, 1136, 1032, 133, 1007, 411, 227, 1155, 148, 762, 647, 519, 230, 441, 238, 987, 28, 254, 528, 367, 858, 1090, 343, 1149, 100, 917, 324, 1037, 640, 985, 147, 7, 1281, 825, 406, 206, 1142, 1026, 539, 127, 1285, 1372, 219, 603, 220, 363, 963, 524, 316, 1242, 1030, 104, 573, 124, 1201, 1056, 779, 27, 527, 202, 943, 214, 225, 1217, 621, 915, 252, 759, 976, 792, 160, 265, 134, 996, 1432, 543, 1184, 1337, 859, 287, 950, 1328, 361, 1252, 1340, 1041, 1039, 156, 882, 1284, 938, 624, 712, 940, 707, 472, 1267, 158, 1436, 518, 1438, 743, 722, 128, 47, 22, 775, 834, 164, 1103, 308, 908, 945, 1430, 348, 1418, 397, 1001, 615, 439, 1401, 120, 378, 884, 912, 1181, 951, 152, 65, 232, 12, 830, 199, 1120, 313, 1339, 761, 955, 927, 922, 904, 334, 1137, 810, 609, 995, 1300, 969, 118, 420, 1336, 1312, 1063, 1025, 425, 1234, 1351, 1320, 38, 235, 1442, 848, 560, 335, 1472, 1097, 304, 1062, 1216, 263, 1381, 452, 1426, 686, 1018, 1319, 243, 1371, 671, 1425, 1346, 180, 693, 550, 402, 702, 508, 1159]\n"
     ]
    }
   ],
   "source": [
    "test_video_indices = test_dataset.indices\n",
    "print(\"Test video IDs:\", test_video_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4056878c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from datetime import datetime\n",
    "\n",
    "model_settings = config.model_settings\n",
    "save_dir = \"~/masters-models\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "save_path = os.path.join(\n",
    "    save_dir,\n",
    "    f\"har_model_{model_settings.model_version}_{model_settings.dataset_prefix}_100perc_{datetime.now()}.pht\"\n",
    ")\n",
    "torch.save({\n",
    "\"model_state_dict\": har_model.state_dict(),\n",
    "\"training_history\": train_history,\n",
    "\"model_config\": har_model._model_config,\n",
    "\"test_set_indices\": test_video_indices,\n",
    "}, save_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8bf73a0",
   "metadata": {},
   "source": [
    "## Running tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe0f60c1",
   "metadata": {},
   "source": [
    "**Accuracy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4a215b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, dataset, device):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i in range(len(dataset)):\n",
    "            sample = dataset[i]\n",
    "            label = sample.label.to(device)\n",
    "\n",
    "            # Move all graph tensors to device\n",
    "            graphs_objects = [g.to(device) for g in sample.graphs_objects]\n",
    "            graphs_joints = [g.to(device) for g in sample.graphs_joints]\n",
    "\n",
    "            # Forward pass\n",
    "            output = model(graphs_objects, graphs_joints)\n",
    "\n",
    "            # Compute prediction\n",
    "            if output.dim() == 1:\n",
    "                predicted = torch.argmax(output).unsqueeze(0)\n",
    "            else:\n",
    "                _, predicted = torch.max(output, dim=1)\n",
    "\n",
    "            correct += (predicted == label).sum().item()\n",
    "            total += 1\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a102aee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 68.14%\n"
     ]
    }
   ],
   "source": [
    "accuracy_evaluation = evaluate(har_model, test_dataset, \"mps\")\n",
    "print(f\"Test Accuracy: {accuracy_evaluation:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
