{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1b2d9ef",
   "metadata": {},
   "source": [
    "# Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84a5065f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading config...\n",
      "Loading secrets...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-27 12:51:23,874 - INFO - Sentry DSN set to: https://f4f21cc936b3ba9f5dbc1464b7a40ea4@o4504168838070272.ingest.us.sentry.io/4506464560414720\n",
      "2025-11-27 12:51:23,875 - INFO - Sentry initialized with environment: development\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import sys\n",
    "sys.path.append(str(Path(os.getcwd()).parent))\n",
    "\n",
    "from settings.global_settings import GlobalSettings\n",
    "\n",
    "config = GlobalSettings.get_config(\n",
    "    config_file = \"../config.ini\",\n",
    "    secrets_file = \"../secrets.ini\"\n",
    ")\n",
    "from dataset.video_loader import VideoDataLoader\n",
    "from dataset.video_dataset import VideoDataset, default_augmentation_pipeline\n",
    "from model.training_loop import train, EarlyStoppingParams\n",
    "from model.multimodal_har_model import MultiModalHARModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b74259d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "OBSERVATION_RATIO = 20\n",
    "EAR_RATIO = OBSERVATION_RATIO / 100\n",
    "WITH_OBJECT_BRANCH = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6cf9b62",
   "metadata": {},
   "source": [
    "## Initializing Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d691d46",
   "metadata": {},
   "source": [
    "**Creating Dataloaders**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d84473d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-27 12:51:25,945 - INFO - [VideoDataLoader] Loding action videos for action: a01\n",
      "2025-11-27 12:51:26,263 - INFO - [VideoDataLoader] Loding action videos for action: a02\n",
      "2025-11-27 12:51:26,605 - INFO - [VideoDataLoader] Loding action videos for action: a03\n",
      "2025-11-27 12:51:26,931 - INFO - [VideoDataLoader] Loding action videos for action: a04\n",
      "2025-11-27 12:51:27,326 - INFO - [VideoDataLoader] Loding action videos for action: a05\n",
      "2025-11-27 12:51:27,547 - INFO - [VideoDataLoader] Loding action videos for action: a06\n",
      "2025-11-27 12:51:27,738 - INFO - [VideoDataLoader] Loding action videos for action: a08\n",
      "2025-11-27 12:51:28,338 - INFO - [VideoDataLoader] Loding action videos for action: a09\n",
      "2025-11-27 12:51:28,811 - INFO - [VideoDataLoader] Loding action videos for action: a11\n",
      "2025-11-27 12:51:29,019 - INFO - [VideoDataLoader] Loding action videos for action: a12\n",
      "2025-11-27 12:51:30,066 - INFO - [VideoDataLoader] Loding action videos for action: a01\n",
      "2025-11-27 12:51:30,092 - INFO - [VideoDataLoader] Loding action videos for action: a02\n",
      "2025-11-27 12:51:30,125 - INFO - [VideoDataLoader] Loding action videos for action: a03\n",
      "2025-11-27 12:51:30,153 - INFO - [VideoDataLoader] Loding action videos for action: a04\n",
      "2025-11-27 12:51:30,185 - INFO - [VideoDataLoader] Loding action videos for action: a05\n",
      "2025-11-27 12:51:30,219 - INFO - [VideoDataLoader] Loding action videos for action: a06\n",
      "2025-11-27 12:51:30,244 - INFO - [VideoDataLoader] Loding action videos for action: a08\n",
      "2025-11-27 12:51:30,306 - INFO - [VideoDataLoader] Loding action videos for action: a09\n",
      "2025-11-27 12:51:30,353 - INFO - [VideoDataLoader] Loding action videos for action: a11\n",
      "2025-11-27 12:51:30,381 - INFO - [VideoDataLoader] Loding action videos for action: a12\n",
      "2025-11-27 12:51:30,485 - INFO - [VideoDataLoader] Loding action videos for action: a01\n",
      "2025-11-27 12:51:30,516 - INFO - [VideoDataLoader] Loding action videos for action: a02\n",
      "2025-11-27 12:51:30,545 - INFO - [VideoDataLoader] Loding action videos for action: a03\n",
      "2025-11-27 12:51:30,564 - INFO - [VideoDataLoader] Loding action videos for action: a04\n",
      "2025-11-27 12:51:30,592 - INFO - [VideoDataLoader] Loding action videos for action: a05\n",
      "2025-11-27 12:51:30,621 - INFO - [VideoDataLoader] Loding action videos for action: a06\n",
      "2025-11-27 12:51:30,649 - INFO - [VideoDataLoader] Loding action videos for action: a08\n",
      "2025-11-27 12:51:30,704 - INFO - [VideoDataLoader] Loding action videos for action: a09\n",
      "2025-11-27 12:51:30,745 - INFO - [VideoDataLoader] Loding action videos for action: a11\n",
      "2025-11-27 12:51:30,775 - INFO - [VideoDataLoader] Loding action videos for action: a12\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "TRAIN_DIR = os.path.join(\n",
    "    config.model_settings.video_data_dir,\n",
    "    \"train\"\n",
    ")\n",
    "TEST_DIR = os.path.join(\n",
    "    config.model_settings.video_data_dir,\n",
    "    \"validation\"\n",
    ")\n",
    "VALIDATION_DIR = os.path.join(\n",
    "    config.model_settings.video_data_dir,\n",
    "    \"test\"\n",
    ")\n",
    "\n",
    "train_video_data_loader = VideoDataLoader(\n",
    "    path=TRAIN_DIR,\n",
    ")\n",
    "test_video_data_loader = VideoDataLoader(\n",
    "    path=TEST_DIR,\n",
    ")\n",
    "validation_video_data_loader = VideoDataLoader(\n",
    "    path=VALIDATION_DIR,\n",
    ")\n",
    "\n",
    "train_dataset = VideoDataset(\n",
    "    video_data_loader=train_video_data_loader,\n",
    "    normalization_type=\"across_frames\",\n",
    "    EAR_ratio=EAR_RATIO,\n",
    "    # transform=default_augmentation_pipeline(target_len=16, noise_std=0.02),\n",
    ")\n",
    "test_dataset = VideoDataset(\n",
    "    video_data_loader=test_video_data_loader,\n",
    "    normalization_type=\"across_frames\",\n",
    "    EAR_ratio=EAR_RATIO,\n",
    ")\n",
    "validation_dataset = VideoDataset(\n",
    "    video_data_loader=validation_video_data_loader,\n",
    "    normalization_type=\"across_frames\",\n",
    "    EAR_ratio=EAR_RATIO,\n",
    ")\n",
    "\n",
    "len(train_dataset)\n",
    "for _ in train_dataset:\n",
    "    pass\n",
    "len(train_dataset.labels_map)\n",
    "\n",
    "len(test_dataset)\n",
    "for _ in test_dataset:\n",
    "    pass\n",
    "\n",
    "len(validation_dataset)\n",
    "for _ in validation_dataset:\n",
    "    pass\n",
    "\n",
    "\n",
    "display(len(test_dataset.labels_map))\n",
    "display(len(validation_dataset.labels_map))\n",
    "display(len(train_dataset.labels_map))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde5336f",
   "metadata": {},
   "source": [
    "**Splitting Train and Test Datasets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0c82257",
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_total = len(train_dataset)\n",
    "# num_train = int(0.8 * num_total)\n",
    "# num_test = num_total - num_train\n",
    "# train_dataset, test_dataset = random_split(train_dataset, [num_train, num_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef613137",
   "metadata": {},
   "source": [
    "**Creating Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "781f5692",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-27 12:51:30,876 - INFO - Model configuration: {'obj_in': 5, 'joint_in': 3, 'gat_hidden': 192, 'gat_out': 192, 'temporal_hidden': 192, 'num_classes': 10, 'dropout': 0.1, 'temporal_pooling': 'attn_pool', 'use_layer_norm': True, 'attention_pooling_heads': 4, 'temporal_transformer_heads': 4, 'use_object_branch': False, 'device': 'cpu'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "attn_heads = 4\n",
    "hidden_size = 192\n",
    "\n",
    "assert hidden_size % attn_heads == 0, \"Hidden size must be divisible by number of attention heads.\"\n",
    "\n",
    "har_model = MultiModalHARModel(\n",
    "    obj_in=train_dataset[0].graphs_objects[0].x.shape[1],\n",
    "    joint_in=train_dataset[0].graphs_joints[0].x.shape[1],\n",
    "    gat_hidden=hidden_size,\n",
    "    gat_out=hidden_size,\n",
    "    temporal_hidden=hidden_size,\n",
    "    num_classes=len(train_dataset.labels_map), \n",
    "    dropout=0.1,\n",
    "    temporal_pooling=\"attn_pool\",\n",
    "    attention_pooling_heads=attn_heads,\n",
    "    temporal_transformer_heads=attn_heads,\n",
    "    use_layer_norm=True,\n",
    "    use_object_branch=WITH_OBJECT_BRANCH, # Testing without object branch\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d8464c4",
   "metadata": {},
   "source": [
    "**Create Evaluate Function For Early Stopping**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a215b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, dataset):\n",
    "    import torch\n",
    "    device = 'cpu'\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i in range(len(dataset)):\n",
    "            sample = dataset[i]\n",
    "            label = sample.label.to(device)\n",
    "\n",
    "            # Move all graph tensors to device\n",
    "            graphs_objects = [g.to(device) for g in sample.graphs_objects]\n",
    "            graphs_joints = [g.to(device) for g in sample.graphs_joints]\n",
    "\n",
    "            # Forward pass\n",
    "            output = model(graphs_objects, graphs_joints)\n",
    "\n",
    "            # Compute prediction\n",
    "            if output.dim() == 1:\n",
    "                predicted = torch.argmax(output).unsqueeze(0)\n",
    "            else:\n",
    "                _, predicted = torch.max(output, dim=1)\n",
    "\n",
    "            correct += (predicted == label).sum().item()\n",
    "            total += 1\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f3ecc27",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_params = EarlyStoppingParams(\n",
    "    patience=20,\n",
    "    min_delta=1e-4,\n",
    "    mode='max',\n",
    "    evaluation_function=evaluate,\n",
    "    evaluation_dataset=validation_dataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bdc50bcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-27 12:51:30,968 - INFO - Starting training loop...\n",
      "2025-11-27 12:51:30,971 - INFO - Using weight decay: 0.0001\n",
      "2025-11-27 12:51:30,972 - INFO - Using Label Smoothing Cross Entropy with smoothing=0.1\n",
      "Epoch 1/90:   0%|          | 0/1176 [00:00<?, ?it/s]/Users/guilhermeleonardonunes/temp/masters-implementation/model/.venv/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:192: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\n",
      "Epoch 1/90: 100%|██████████| 1176/1176 [00:27<00:00, 42.97it/s]\n",
      "2025-11-27 12:51:58,359 - INFO - Epoch 1/90, Loss: 2.1754\n",
      "Epoch 2/90: 100%|██████████| 1176/1176 [00:21<00:00, 54.34it/s]\n",
      "2025-11-27 12:52:20,002 - INFO - Epoch 2/90, Loss: 2.0585\n",
      "Epoch 3/90: 100%|██████████| 1176/1176 [00:26<00:00, 44.98it/s]\n",
      "2025-11-27 12:52:46,151 - INFO - Epoch 3/90, Loss: 2.0229\n",
      "Epoch 4/90: 100%|██████████| 1176/1176 [00:21<00:00, 53.47it/s]\n",
      "2025-11-27 12:53:08,149 - INFO - Epoch 4/90, Loss: 1.9890\n",
      "Epoch 5/90: 100%|██████████| 1176/1176 [00:21<00:00, 53.63it/s]\n",
      "2025-11-27 12:53:30,080 - INFO - Epoch 5/90, Loss: 1.9740\n",
      "Epoch 6/90: 100%|██████████| 1176/1176 [00:26<00:00, 44.78it/s]\n",
      "2025-11-27 12:53:56,344 - INFO - Epoch 6/90, Loss: 1.9523\n",
      "Epoch 7/90: 100%|██████████| 1176/1176 [00:21<00:00, 53.93it/s]\n",
      "2025-11-27 12:54:18,156 - INFO - Epoch 7/90, Loss: 1.9373\n",
      "Epoch 8/90: 100%|██████████| 1176/1176 [00:27<00:00, 42.97it/s]\n",
      "2025-11-27 12:54:45,527 - INFO - Epoch 8/90, Loss: 1.9056\n",
      "Epoch 9/90: 100%|██████████| 1176/1176 [00:22<00:00, 52.36it/s]\n",
      "2025-11-27 12:55:07,990 - INFO - Epoch 9/90, Loss: 1.8859\n",
      "Epoch 10/90: 100%|██████████| 1176/1176 [00:21<00:00, 53.56it/s]\n",
      "2025-11-27 12:55:29,948 - INFO - Epoch 10/90, Loss: 1.8808\n",
      "Epoch 11/90: 100%|██████████| 1176/1176 [00:27<00:00, 42.89it/s]\n",
      "2025-11-27 12:55:57,369 - INFO - Epoch 11/90, Loss: 1.8700\n",
      "Epoch 12/90: 100%|██████████| 1176/1176 [00:22<00:00, 53.13it/s]\n",
      "2025-11-27 12:56:19,507 - INFO - Epoch 12/90, Loss: 1.8329\n",
      "Epoch 13/90: 100%|██████████| 1176/1176 [00:26<00:00, 43.75it/s]\n",
      "2025-11-27 12:56:46,387 - INFO - Epoch 13/90, Loss: 1.8219\n",
      "Epoch 14/90: 100%|██████████| 1176/1176 [00:22<00:00, 51.71it/s]\n",
      "2025-11-27 12:57:09,134 - INFO - Epoch 14/90, Loss: 1.8081\n",
      "Epoch 15/90: 100%|██████████| 1176/1176 [00:21<00:00, 53.69it/s]\n",
      "2025-11-27 12:57:31,039 - INFO - Epoch 15/90, Loss: 1.8024\n",
      "Epoch 16/90: 100%|██████████| 1176/1176 [00:26<00:00, 43.70it/s]\n",
      "2025-11-27 12:57:57,954 - INFO - Epoch 16/90, Loss: 1.7877\n",
      "Epoch 17/90: 100%|██████████| 1176/1176 [00:22<00:00, 53.04it/s]\n",
      "2025-11-27 12:58:20,127 - INFO - Epoch 17/90, Loss: 1.7688\n",
      "Epoch 18/90: 100%|██████████| 1176/1176 [00:27<00:00, 43.11it/s]\n",
      "2025-11-27 12:58:47,410 - INFO - Epoch 18/90, Loss: 1.7494\n",
      "Epoch 19/90: 100%|██████████| 1176/1176 [00:22<00:00, 52.22it/s]\n",
      "2025-11-27 12:59:09,935 - INFO - Epoch 19/90, Loss: 1.7460\n",
      "Epoch 20/90: 100%|██████████| 1176/1176 [00:23<00:00, 50.51it/s]\n",
      "2025-11-27 12:59:33,230 - INFO - Epoch 20/90, Loss: 1.7309\n",
      "Epoch 21/90: 100%|██████████| 1176/1176 [00:26<00:00, 44.69it/s]\n",
      "2025-11-27 12:59:59,549 - INFO - Epoch 21/90, Loss: 1.6992\n",
      "Epoch 22/90: 100%|██████████| 1176/1176 [00:22<00:00, 53.03it/s]\n",
      "2025-11-27 13:00:21,730 - INFO - Epoch 22/90, Loss: 1.6861\n",
      "Epoch 23/90: 100%|██████████| 1176/1176 [00:26<00:00, 43.60it/s]\n",
      "2025-11-27 13:00:48,706 - INFO - Epoch 23/90, Loss: 1.6781\n",
      "Epoch 24/90: 100%|██████████| 1176/1176 [00:21<00:00, 53.55it/s]\n",
      "2025-11-27 13:01:10,672 - INFO - Epoch 24/90, Loss: 1.6611\n",
      "Epoch 25/90: 100%|██████████| 1176/1176 [00:26<00:00, 44.55it/s]\n",
      "2025-11-27 13:01:37,072 - INFO - Epoch 25/90, Loss: 1.6316\n",
      "Epoch 26/90: 100%|██████████| 1176/1176 [00:23<00:00, 49.97it/s]\n",
      "2025-11-27 13:02:00,609 - INFO - Epoch 26/90, Loss: 1.6319\n",
      "Epoch 27/90: 100%|██████████| 1176/1176 [00:22<00:00, 52.81it/s]\n",
      "2025-11-27 13:02:22,881 - INFO - Epoch 27/90, Loss: 1.5818\n",
      "Epoch 28/90: 100%|██████████| 1176/1176 [00:27<00:00, 43.09it/s]\n",
      "2025-11-27 13:02:50,173 - INFO - Epoch 28/90, Loss: 1.5949\n",
      "Epoch 29/90: 100%|██████████| 1176/1176 [00:22<00:00, 52.18it/s]\n",
      "2025-11-27 13:03:12,713 - INFO - Epoch 29/90, Loss: 1.5768\n",
      "Epoch 30/90: 100%|██████████| 1176/1176 [00:26<00:00, 44.91it/s]\n",
      "2025-11-27 13:03:38,904 - INFO - Epoch 30/90, Loss: 1.5324\n",
      "Epoch 31/90: 100%|██████████| 1176/1176 [00:22<00:00, 51.23it/s]\n",
      "2025-11-27 13:04:01,862 - INFO - Epoch 31/90, Loss: 1.5366\n",
      "Epoch 32/90: 100%|██████████| 1176/1176 [00:22<00:00, 53.02it/s]\n",
      "2025-11-27 13:04:24,046 - INFO - Epoch 32/90, Loss: 1.5151\n",
      "Epoch 33/90: 100%|██████████| 1176/1176 [00:27<00:00, 43.25it/s]\n",
      "2025-11-27 13:04:51,241 - INFO - Epoch 33/90, Loss: 1.4873\n",
      "Epoch 34/90: 100%|██████████| 1176/1176 [00:21<00:00, 53.75it/s]\n",
      "2025-11-27 13:05:13,121 - INFO - Epoch 34/90, Loss: 1.4910\n",
      "Epoch 35/90: 100%|██████████| 1176/1176 [00:26<00:00, 45.17it/s]\n",
      "2025-11-27 13:05:39,158 - INFO - Epoch 35/90, Loss: 1.4592\n",
      "Epoch 36/90: 100%|██████████| 1176/1176 [00:23<00:00, 50.86it/s]\n",
      "2025-11-27 13:06:02,285 - INFO - Epoch 36/90, Loss: 1.4410\n",
      "Epoch 37/90: 100%|██████████| 1176/1176 [00:21<00:00, 54.09it/s]\n",
      "2025-11-27 13:06:24,028 - INFO - Epoch 37/90, Loss: 1.4359\n",
      "Epoch 38/90: 100%|██████████| 1176/1176 [00:27<00:00, 42.48it/s]\n",
      "2025-11-27 13:06:51,711 - INFO - Epoch 38/90, Loss: 1.4189\n",
      "Epoch 39/90: 100%|██████████| 1176/1176 [00:21<00:00, 53.49it/s]\n",
      "2025-11-27 13:07:13,699 - INFO - Epoch 39/90, Loss: 1.4184\n",
      "Epoch 40/90: 100%|██████████| 1176/1176 [00:25<00:00, 46.38it/s]\n",
      "2025-11-27 13:07:39,056 - INFO - Epoch 40/90, Loss: 1.3967\n",
      "Epoch 41/90: 100%|██████████| 1176/1176 [00:22<00:00, 51.42it/s]\n",
      "2025-11-27 13:08:01,929 - INFO - Epoch 41/90, Loss: 1.3660\n",
      "Epoch 42/90: 100%|██████████| 1176/1176 [00:21<00:00, 53.79it/s]\n",
      "2025-11-27 13:08:23,796 - INFO - Epoch 42/90, Loss: 1.3572\n",
      "Epoch 43/90: 100%|██████████| 1176/1176 [00:28<00:00, 41.74it/s]\n",
      "2025-11-27 13:08:51,976 - INFO - Epoch 43/90, Loss: 1.3576\n",
      "Epoch 44/90: 100%|██████████| 1176/1176 [00:22<00:00, 53.16it/s]\n",
      "2025-11-27 13:09:14,101 - INFO - Epoch 44/90, Loss: 1.3429\n",
      "Epoch 45/90: 100%|██████████| 1176/1176 [00:26<00:00, 43.72it/s]\n",
      "2025-11-27 13:09:41,004 - INFO - Epoch 45/90, Loss: 1.3217\n",
      "Epoch 46/90: 100%|██████████| 1176/1176 [00:23<00:00, 50.64it/s]\n",
      "2025-11-27 13:10:04,229 - INFO - Epoch 46/90, Loss: 1.3018\n",
      "Epoch 47/90: 100%|██████████| 1176/1176 [00:21<00:00, 54.69it/s]\n",
      "2025-11-27 13:10:25,736 - INFO - Epoch 47/90, Loss: 1.2933\n",
      "Epoch 48/90: 100%|██████████| 1176/1176 [00:27<00:00, 42.28it/s]\n",
      "2025-11-27 13:10:53,554 - INFO - Epoch 48/90, Loss: 1.2758\n",
      "Epoch 49/90: 100%|██████████| 1176/1176 [00:22<00:00, 52.90it/s]\n",
      "2025-11-27 13:11:15,790 - INFO - Epoch 49/90, Loss: 1.2751\n",
      "Epoch 50/90: 100%|██████████| 1176/1176 [00:26<00:00, 44.29it/s]\n",
      "2025-11-27 13:11:42,345 - INFO - Epoch 50/90, Loss: 1.2485\n",
      "Epoch 51/90: 100%|██████████| 1176/1176 [00:24<00:00, 48.30it/s]\n",
      "2025-11-27 13:12:06,696 - INFO - Epoch 51/90, Loss: 1.2434\n",
      "Epoch 52/90: 100%|██████████| 1176/1176 [00:21<00:00, 53.89it/s]\n",
      "2025-11-27 13:12:28,519 - INFO - Epoch 52/90, Loss: 1.2342\n",
      "Epoch 53/90: 100%|██████████| 1176/1176 [00:28<00:00, 41.65it/s]\n",
      "2025-11-27 13:12:56,758 - INFO - Epoch 53/90, Loss: 1.1902\n",
      "Epoch 54/90: 100%|██████████| 1176/1176 [00:23<00:00, 50.96it/s]\n",
      "2025-11-27 13:13:19,837 - INFO - Epoch 54/90, Loss: 1.1681\n",
      "Epoch 55/90: 100%|██████████| 1176/1176 [00:29<00:00, 40.38it/s]\n",
      "2025-11-27 13:13:48,960 - INFO - Epoch 55/90, Loss: 1.2233\n",
      "Epoch 56/90: 100%|██████████| 1176/1176 [00:23<00:00, 50.63it/s]\n",
      "2025-11-27 13:14:12,191 - INFO - Epoch 56/90, Loss: 1.1671\n",
      "Epoch 57/90: 100%|██████████| 1176/1176 [00:34<00:00, 34.24it/s]\n",
      "2025-11-27 13:14:46,537 - INFO - Epoch 57/90, Loss: 1.1469\n",
      "Epoch 58/90: 100%|██████████| 1176/1176 [00:24<00:00, 48.14it/s]\n",
      "2025-11-27 13:15:10,968 - INFO - Epoch 58/90, Loss: 1.1515\n",
      "Epoch 59/90: 100%|██████████| 1176/1176 [00:26<00:00, 45.03it/s]\n",
      "2025-11-27 13:15:37,088 - INFO - Epoch 59/90, Loss: 1.1440\n",
      "Epoch 60/90: 100%|██████████| 1176/1176 [00:24<00:00, 47.60it/s]\n",
      "2025-11-27 13:16:01,795 - INFO - Epoch 60/90, Loss: 1.1093\n",
      "Epoch 61/90: 100%|██████████| 1176/1176 [00:22<00:00, 52.18it/s]\n",
      "2025-11-27 13:16:24,337 - INFO - Epoch 61/90, Loss: 1.1243\n",
      "Epoch 62/90: 100%|██████████| 1176/1176 [00:28<00:00, 41.54it/s]\n",
      "2025-11-27 13:16:52,649 - INFO - Epoch 62/90, Loss: 1.1041\n",
      "Epoch 63/90: 100%|██████████| 1176/1176 [00:22<00:00, 52.53it/s]\n",
      "2025-11-27 13:17:15,046 - INFO - Epoch 63/90, Loss: 1.0975\n",
      "Epoch 64/90: 100%|██████████| 1176/1176 [00:25<00:00, 46.00it/s]\n",
      "2025-11-27 13:17:40,616 - INFO - Epoch 64/90, Loss: 1.0799\n",
      "Epoch 65/90: 100%|██████████| 1176/1176 [00:22<00:00, 51.39it/s]\n",
      "2025-11-27 13:18:03,503 - INFO - Epoch 65/90, Loss: 1.0745\n",
      "Epoch 66/90: 100%|██████████| 1176/1176 [00:23<00:00, 51.09it/s]\n",
      "2025-11-27 13:18:26,525 - INFO - Epoch 66/90, Loss: 1.0963\n",
      "Epoch 67/90: 100%|██████████| 1176/1176 [00:28<00:00, 41.38it/s]\n",
      "2025-11-27 13:18:54,947 - INFO - Epoch 67/90, Loss: 1.0531\n",
      "Epoch 68/90: 100%|██████████| 1176/1176 [00:22<00:00, 51.14it/s]\n",
      "2025-11-27 13:19:17,945 - INFO - Epoch 68/90, Loss: 1.0515\n",
      "Epoch 69/90: 100%|██████████| 1176/1176 [00:29<00:00, 39.40it/s]\n",
      "2025-11-27 13:19:47,802 - INFO - Epoch 69/90, Loss: 1.0460\n",
      "Epoch 70/90: 100%|██████████| 1176/1176 [00:22<00:00, 52.22it/s]\n",
      "2025-11-27 13:20:10,334 - INFO - Epoch 70/90, Loss: 1.0318\n",
      "Epoch 71/90: 100%|██████████| 1176/1176 [00:26<00:00, 44.21it/s]\n",
      "2025-11-27 13:20:36,938 - INFO - Epoch 71/90, Loss: 1.0085\n",
      "Epoch 72/90: 100%|██████████| 1176/1176 [00:24<00:00, 47.40it/s]\n",
      "2025-11-27 13:21:01,754 - INFO - Epoch 72/90, Loss: 1.0310\n",
      "Epoch 73/90: 100%|██████████| 1176/1176 [00:22<00:00, 52.65it/s]\n",
      "2025-11-27 13:21:24,095 - INFO - Epoch 73/90, Loss: 0.9975\n",
      "Epoch 74/90: 100%|██████████| 1176/1176 [00:27<00:00, 43.45it/s]\n",
      "2025-11-27 13:21:51,165 - INFO - Epoch 74/90, Loss: 1.0155\n",
      "Epoch 75/90: 100%|██████████| 1176/1176 [00:22<00:00, 52.14it/s]\n",
      "2025-11-27 13:22:13,725 - INFO - Epoch 75/90, Loss: 0.9844\n",
      "Epoch 76/90: 100%|██████████| 1176/1176 [00:26<00:00, 45.00it/s]\n",
      "2025-11-27 13:22:39,864 - INFO - Epoch 76/90, Loss: 0.9759\n",
      "Epoch 77/90: 100%|██████████| 1176/1176 [00:23<00:00, 50.99it/s]\n",
      "2025-11-27 13:23:02,932 - INFO - Epoch 77/90, Loss: 0.9877\n",
      "Epoch 78/90: 100%|██████████| 1176/1176 [00:22<00:00, 53.10it/s]\n",
      "2025-11-27 13:23:25,080 - INFO - Epoch 78/90, Loss: 0.9599\n",
      "Epoch 79/90: 100%|██████████| 1176/1176 [00:26<00:00, 44.66it/s]\n",
      "2025-11-27 13:23:51,418 - INFO - Epoch 79/90, Loss: 1.0041\n",
      "Epoch 80/90: 100%|██████████| 1176/1176 [00:22<00:00, 52.81it/s]\n",
      "2025-11-27 13:24:13,689 - INFO - Epoch 80/90, Loss: 0.9545\n",
      "Epoch 81/90: 100%|██████████| 1176/1176 [00:26<00:00, 44.31it/s]\n",
      "2025-11-27 13:24:40,236 - INFO - Epoch 81/90, Loss: 0.9536\n",
      "Epoch 82/90: 100%|██████████| 1176/1176 [00:23<00:00, 49.90it/s]\n",
      "2025-11-27 13:25:03,810 - INFO - Epoch 82/90, Loss: 0.9465\n",
      "Epoch 83/90: 100%|██████████| 1176/1176 [00:21<00:00, 54.25it/s]\n",
      "2025-11-27 13:25:25,492 - INFO - Epoch 83/90, Loss: 0.9383\n",
      "Epoch 84/90: 100%|██████████| 1176/1176 [00:27<00:00, 43.09it/s]\n",
      "2025-11-27 13:25:52,789 - INFO - Epoch 84/90, Loss: 0.9309\n",
      "Epoch 85/90: 100%|██████████| 1176/1176 [00:21<00:00, 53.50it/s]\n",
      "2025-11-27 13:26:14,775 - INFO - Epoch 85/90, Loss: 0.9245\n",
      "Epoch 86/90: 100%|██████████| 1176/1176 [00:25<00:00, 46.05it/s]\n",
      "2025-11-27 13:26:40,316 - INFO - Epoch 86/90, Loss: 0.9202\n",
      "Epoch 87/90: 100%|██████████| 1176/1176 [00:23<00:00, 51.08it/s]\n",
      "2025-11-27 13:27:03,346 - INFO - Epoch 87/90, Loss: 0.9196\n",
      "Epoch 88/90: 100%|██████████| 1176/1176 [00:21<00:00, 53.48it/s]\n",
      "2025-11-27 13:27:25,337 - INFO - Epoch 88/90, Loss: 0.9232\n",
      "Epoch 89/90: 100%|██████████| 1176/1176 [00:27<00:00, 43.48it/s]\n",
      "2025-11-27 13:27:52,386 - INFO - Epoch 89/90, Loss: 0.8926\n",
      "Epoch 90/90: 100%|██████████| 1176/1176 [00:22<00:00, 53.45it/s]\n",
      "2025-11-27 13:28:14,399 - INFO - Epoch 90/90, Loss: 0.9198\n"
     ]
    }
   ],
   "source": [
    "from model.training_loop import WarmupSchedulerParams\n",
    "\n",
    "\n",
    "train_history = train(\n",
    "    model=har_model,\n",
    "    video_dataset=train_dataset,\n",
    "    device='cpu',\n",
    "    # epochs=120,\n",
    "    epochs=90,\n",
    "    lr=1e-4,\n",
    "    weight_decay=1e-4,\n",
    "    # early_stopping=early_stopping_params,\n",
    "    warmup_scheduler_params=WarmupSchedulerParams(True, 400),\n",
    "    cross_entropy_label_smoothing=0.1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33cabcd9",
   "metadata": {},
   "source": [
    "## Training Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde2e009",
   "metadata": {},
   "source": [
    "**Early Stopping**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d6abf28",
   "metadata": {},
   "source": [
    "**Training**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd5bc8d",
   "metadata": {},
   "source": [
    "**Saving Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "66b74bb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-27 13:28:14,497 - INFO - Saving model to /Volumes/KODAK/masters/model/validation_datasets/NW-UCLA/model/har_model_v1.0.1_nw_ucla_20_no_obj_20251127_132814.pht...\n",
      "2025-11-27 13:28:14,792 - INFO - Model saved successfully.\n"
     ]
    }
   ],
   "source": [
    "har_model.save(\n",
    "    training_history=train_history,\n",
    "    EAR_ratio=EAR_RATIO,\n",
    "    with_object_branch=WITH_OBJECT_BRANCH,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8bf73a0",
   "metadata": {},
   "source": [
    "## Running tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe0f60c1",
   "metadata": {},
   "source": [
    "**Accuracy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a102aee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 30.26%\n"
     ]
    }
   ],
   "source": [
    "accuracy_evaluation = evaluate(har_model, test_dataset)\n",
    "print(f\"Test Accuracy: {accuracy_evaluation:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "265d4d4d",
   "metadata": {},
   "source": [
    "## Debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1f9a2abf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out.shape torch.Size([1, 10])\n",
      "out device cpu label device cpu\n",
      "logits: [[ 2.138848   -1.4557503   0.18490607 -3.3747542  -0.63881165 -2.5294802\n",
      "  -2.743491   -2.8771312  -3.1752052  -4.603438  ]]\n",
      "probs: [[0.7904503  0.02171502 0.11201812 0.00318675 0.04915326 0.00742071\n",
      "  0.00599103 0.00524158 0.00389054 0.00093269]]\n",
      "entropy: 0.8033349514007568\n",
      "pred: 0 label: 0\n"
     ]
    }
   ],
   "source": [
    "import torch, torch.nn.functional as F\n",
    "device = 'cpu'   # match training device\n",
    "har_model.to(device)\n",
    "har_model.eval()\n",
    "\n",
    "sample = train_dataset[0]\n",
    "graphs_objects = [g.to(device) for g in sample.graphs_objects]\n",
    "graphs_joints = [g.to(device) for g in sample.graphs_joints]\n",
    "label = sample.label.unsqueeze(0).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    out = har_model(graphs_objects, graphs_joints)   # expect [1, num_classes]\n",
    "    probs = F.softmax(out, dim=-1)\n",
    "    ent = -(probs * probs.log()).sum(dim=-1)     # entropy\n",
    "    pred = torch.argmax(probs, dim=-1)\n",
    "\n",
    "print(\"out.shape\", out.shape)\n",
    "print(\"out device\", out.device, \"label device\", label.device)\n",
    "print(\"logits:\", out.cpu().numpy())\n",
    "print(\"probs:\", probs.cpu().numpy())\n",
    "print(\"entropy:\", ent.item())\n",
    "print(\"pred:\", pred.item(), \"label:\", label.item())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a7199e",
   "metadata": {},
   "source": [
    "**Mapping Consistency - Distribution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9da92364",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TRAIN ===\n",
      "len: 1176\n",
      "unique labels: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "counts: Counter({3: 138, 5: 119, 0: 118, 4: 118, 1: 116, 8: 116, 6: 113, 7: 113, 9: 113, 2: 112})\n",
      "labels_map (sample): {'a01': 0, 'a02': 1, 'a03': 2, 'a04': 3, 'a05': 4, 'a06': 5, 'a08': 6, 'a09': 7, 'a11': 8, 'a12': 9}\n",
      "\n",
      "=== VAL ===\n",
      "len: 147\n",
      "unique labels: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "counts: Counter({3: 17, 0: 15, 1: 15, 4: 15, 5: 15, 2: 14, 6: 14, 7: 14, 8: 14, 9: 14})\n",
      "labels_map (sample): {'a01': 0, 'a02': 1, 'a03': 2, 'a04': 3, 'a05': 4, 'a06': 5, 'a08': 6, 'a09': 7, 'a11': 8, 'a12': 9}\n",
      "\n",
      "=== TEST ===\n",
      "len: 152\n",
      "unique labels: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "counts: Counter({3: 18, 0: 15, 1: 15, 4: 15, 5: 15, 6: 15, 7: 15, 8: 15, 9: 15, 2: 14})\n",
      "labels_map (sample): {'a01': 0, 'a02': 1, 'a03': 2, 'a04': 3, 'a05': 4, 'a06': 5, 'a08': 6, 'a09': 7, 'a11': 8, 'a12': 9}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "def inspect_dataset(dataset, name):\n",
    "    labels = [int(s.label) for s in dataset]\n",
    "    print(f\"=== {name} ===\")\n",
    "    print(\"len:\", len(labels))\n",
    "    print(\"unique labels:\", sorted(set(labels)))\n",
    "    print(\"counts:\", Counter(labels))\n",
    "    print(\"labels_map (sample):\", getattr(dataset, \"labels_map\", None))\n",
    "    print()\n",
    "\n",
    "inspect_dataset(train_dataset, \"TRAIN\")\n",
    "inspect_dataset(validation_dataset, \"VAL\")\n",
    "inspect_dataset(test_dataset, \"TEST\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a023a48",
   "metadata": {},
   "source": [
    "**Prediction Distribution - Predicts only few classes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ac297c99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred distribution: Counter({9: 22, 0: 17, 4: 17, 5: 17, 3: 14, 1: 14, 7: 13, 8: 13, 2: 11, 6: 9})\n",
      "true distribution : Counter({3: 17, 0: 15, 1: 15, 4: 15, 5: 15, 2: 14, 6: 14, 7: 14, 8: 14, 9: 14})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import torch, torch.nn.functional as F\n",
    "\n",
    "def pred_distribution(model, dataset, device='cpu'):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    truths = []\n",
    "    with torch.no_grad():\n",
    "        for s in dataset:\n",
    "            graphs_objects = [g.to(device) for g in s.graphs_objects]\n",
    "            graphs_joints  = [g.to(device) for g in s.graphs_joints]\n",
    "            out = model(graphs_objects, graphs_joints)  # [1, C]\n",
    "            preds.append(int(torch.argmax(out, dim=-1)))\n",
    "            truths.append(int(s.label))\n",
    "    print(\"pred distribution:\", Counter(preds))\n",
    "    print(\"true distribution :\", Counter(truths))\n",
    "    return preds, truths\n",
    "\n",
    "preds, truths = pred_distribution(har_model, validation_dataset, device='cpu')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebdd34ac",
   "metadata": {},
   "source": [
    "**Confusion Matrix - Per Class Prediction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "edb7bd7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      " [[4 4 2 2 2 0 0 1 0 0]\n",
      " [5 4 0 0 2 1 0 1 1 1]\n",
      " [1 0 0 3 1 3 0 0 3 3]\n",
      " [1 0 0 3 0 6 0 0 1 6]\n",
      " [1 3 4 1 2 0 0 0 0 4]\n",
      " [1 0 1 1 5 5 0 0 2 0]\n",
      " [1 1 0 0 0 0 7 4 0 1]\n",
      " [0 0 0 3 0 0 2 7 2 0]\n",
      " [2 1 2 0 5 0 0 0 0 4]\n",
      " [1 1 2 1 0 2 0 0 4 3]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.2353    0.2667    0.2500        15\n",
      "           1     0.2857    0.2667    0.2759        15\n",
      "           2     0.0000    0.0000    0.0000        14\n",
      "           3     0.2143    0.1765    0.1935        17\n",
      "           4     0.1176    0.1333    0.1250        15\n",
      "           5     0.2941    0.3333    0.3125        15\n",
      "           6     0.7778    0.5000    0.6087        14\n",
      "           7     0.5385    0.5000    0.5185        14\n",
      "           8     0.0000    0.0000    0.0000        14\n",
      "           9     0.1364    0.2143    0.1667        14\n",
      "\n",
      "    accuracy                         0.2381       147\n",
      "   macro avg     0.2600    0.2391    0.2451       147\n",
      "weighted avg     0.2583    0.2381    0.2439       147\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "cm = confusion_matrix(truths, preds)\n",
    "print(\"Confusion matrix:\\n\", cm)\n",
    "print(classification_report(truths, preds, digits=4))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
