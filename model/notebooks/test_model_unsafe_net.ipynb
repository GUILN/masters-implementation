{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1b2d9ef",
   "metadata": {},
   "source": [
    "# Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84a5065f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading config...\n",
      "Loading secrets...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-07 22:42:52,057 - INFO - Sentry DSN set to: https://f4f21cc936b3ba9f5dbc1464b7a40ea4@o4504168838070272.ingest.us.sentry.io/4506464560414720\n",
      "2025-12-07 22:42:52,058 - INFO - Sentry initialized with environment: development\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import sys\n",
    "sys.path.append(str(Path(os.getcwd()).parent))\n",
    "\n",
    "from settings.global_settings import GlobalSettings\n",
    "\n",
    "config = GlobalSettings.get_config(\n",
    "    config_file = \"../config.ini\",\n",
    "    secrets_file = \"../secrets.ini\"\n",
    ")\n",
    "from dataset.video_loader import VideoDataLoader\n",
    "from dataset.video_dataset import VideoDataset, default_augmentation_pipeline\n",
    "from model.training_loop import train, EarlyStoppingParams\n",
    "from model.multimodal_har_model import MultiModalHARModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b74259d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "OBSERVATION_RATIO = 20\n",
    "EAR_RATIO = OBSERVATION_RATIO / 100\n",
    "WITH_OBJECT_BRANCH = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6cf9b62",
   "metadata": {},
   "source": [
    "## Initializing Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d691d46",
   "metadata": {},
   "source": [
    "**Creating Dataloaders**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d84473d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-07 22:42:54,037 - INFO - [VideoDataLoader] Loding action videos for action: 0_safe_walkway_violation\n",
      "2025-12-07 22:42:54,603 - INFO - [VideoDataLoader] Loding action videos for action: 1_unauthorized_intervention\n",
      "2025-12-07 22:42:54,947 - INFO - [VideoDataLoader] Loding action videos for action: 2_opened_panel cover\n",
      "2025-12-07 22:42:55,280 - INFO - [VideoDataLoader] Loding action videos for action: 3_carrying_overload_with_forklift\n",
      "2025-12-07 22:42:55,373 - INFO - [VideoDataLoader] Loding action videos for action: 4_safe_walkway\n",
      "2025-12-07 22:42:55,490 - INFO - [VideoDataLoader] Loding action videos for action: 5_authorized_intervention\n",
      "2025-12-07 22:42:55,799 - INFO - [VideoDataLoader] Loding action videos for action: 6_closed_panel_cover\n",
      "2025-12-07 22:42:55,851 - INFO - [VideoDataLoader] Loding action videos for action: 7_safe_carrying\n",
      "2025-12-07 22:42:56,674 - INFO - [VideoDataLoader] Loding action videos for action: 0_safe_walkway_violation\n",
      "2025-12-07 22:42:56,780 - INFO - [VideoDataLoader] Loding action videos for action: 1_unauthorized_intervention\n",
      "2025-12-07 22:42:56,818 - INFO - [VideoDataLoader] Loding action videos for action: 2_opened_panel cover\n",
      "2025-12-07 22:42:56,846 - INFO - [VideoDataLoader] Loding action videos for action: 3_carrying_overload_with_forklift\n",
      "2025-12-07 22:42:56,867 - INFO - [VideoDataLoader] Loding action videos for action: 4_safe_walkway\n",
      "2025-12-07 22:42:56,930 - INFO - [VideoDataLoader] Loding action videos for action: 5_authorized_intervention\n",
      "2025-12-07 22:42:57,394 - INFO - [VideoDataLoader] Loding action videos for action: 6_closed_panel_cover\n",
      "2025-12-07 22:42:57,417 - INFO - [VideoDataLoader] Loding action videos for action: 7_safe_carrying\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "TRAIN_DIR = os.path.join(\n",
    "    config.model_settings.video_data_dir,\n",
    "    \"train\"\n",
    ")\n",
    "TEST_DIR = os.path.join(\n",
    "    config.model_settings.video_data_dir,\n",
    "    \"test\"\n",
    ")\n",
    "\n",
    "\n",
    "train_video_data_loader = VideoDataLoader(\n",
    "    path=TRAIN_DIR,\n",
    ")\n",
    "test_video_data_loader = VideoDataLoader(\n",
    "    path=TEST_DIR,\n",
    ")\n",
    "\n",
    "\n",
    "train_dataset = VideoDataset(\n",
    "    video_data_loader=train_video_data_loader,\n",
    "    normalization_type=\"across_frames\",\n",
    "    EAR_ratio=EAR_RATIO,\n",
    "    # transform=default_augmentation_pipeline(target_len=16, noise_std=0.02),\n",
    ")\n",
    "test_dataset = VideoDataset(\n",
    "    video_data_loader=test_video_data_loader,\n",
    "    normalization_type=\"across_frames\",\n",
    "    EAR_ratio=EAR_RATIO,\n",
    ")\n",
    "\n",
    "\n",
    "len(train_dataset)\n",
    "for _ in train_dataset:\n",
    "    pass\n",
    "len(train_dataset.labels_map)\n",
    "\n",
    "len(test_dataset)\n",
    "for _ in test_dataset:\n",
    "    pass\n",
    "\n",
    "\n",
    "display(len(test_dataset.labels_map))\n",
    "display(len(train_dataset.labels_map))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde5336f",
   "metadata": {},
   "source": [
    "**Splitting Train and Test Datasets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0c82257",
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_total = len(train_dataset)\n",
    "# num_train = int(0.8 * num_total)\n",
    "# num_test = num_total - num_train\n",
    "# train_dataset, test_dataset = random_split(train_dataset, [num_train, num_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef613137",
   "metadata": {},
   "source": [
    "**Creating Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "781f5692",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-07 22:42:57,536 - INFO - Model configuration: {'obj_in': 5, 'joint_in': 3, 'gat_hidden': 192, 'gat_out': 192, 'temporal_hidden': 192, 'num_classes': 8, 'dropout': 0.1, 'temporal_pooling': 'attn_pool', 'use_layer_norm': True, 'attention_pooling_heads': 4, 'temporal_transformer_heads': 4, 'use_object_branch': False, 'device': 'cpu'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "attn_heads = 4\n",
    "hidden_size = 192\n",
    "\n",
    "assert hidden_size % attn_heads == 0, \"Hidden size must be divisible by number of attention heads.\"\n",
    "\n",
    "har_model = MultiModalHARModel(\n",
    "    obj_in=train_dataset[0].graphs_objects[0].x.shape[1],\n",
    "    joint_in=train_dataset[0].graphs_joints[0].x.shape[1],\n",
    "    gat_hidden=hidden_size,\n",
    "    gat_out=hidden_size,\n",
    "    temporal_hidden=hidden_size,\n",
    "    num_classes=len(train_dataset.labels_map), \n",
    "    dropout=0.1,\n",
    "    temporal_pooling=\"attn_pool\",\n",
    "    attention_pooling_heads=attn_heads,\n",
    "    temporal_transformer_heads=attn_heads,\n",
    "    use_layer_norm=True,\n",
    "    use_object_branch=WITH_OBJECT_BRANCH, # Testing without object branch\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d8464c4",
   "metadata": {},
   "source": [
    "**Create Evaluate Function For Early Stopping**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a215b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from validation.quantitative_metrics import evaluate_model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def evaluate_model_with_auc(model, dataset):\n",
    "    return evaluate_model(model, dataset, device).accuracy\n",
    "\n",
    "def evaluate(model, dataset):\n",
    "    import torch\n",
    "    device = 'cpu'\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i in range(len(dataset)):\n",
    "            sample = dataset[i]\n",
    "            label = sample.label.to(device)\n",
    "\n",
    "            # Move all graph tensors to device\n",
    "            graphs_objects = [g.to(device) for g in sample.graphs_objects]\n",
    "            graphs_joints = [g.to(device) for g in sample.graphs_joints]\n",
    "\n",
    "            # Forward pass\n",
    "            output = model(graphs_objects, graphs_joints)\n",
    "\n",
    "            # Compute prediction\n",
    "            if output.dim() == 1:\n",
    "                predicted = torch.argmax(output).unsqueeze(0)\n",
    "            else:\n",
    "                _, predicted = torch.max(output, dim=1)\n",
    "\n",
    "            correct += (predicted == label).sum().item()\n",
    "            total += 1\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f3ecc27",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_params = EarlyStoppingParams(\n",
    "    patience=20,\n",
    "    min_delta=1e-4,\n",
    "    mode='max',\n",
    "    evaluation_function=evaluate_model_with_auc,\n",
    "    evaluation_dataset=test_dataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bdc50bcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-07 22:42:58,900 - INFO - Starting training loop...\n",
      "2025-12-07 22:42:58,903 - INFO - Using weight decay: 0.0001\n",
      "2025-12-07 22:42:58,903 - INFO - Using Label Smoothing Cross Entropy with smoothing=0.1\n",
      "Epoch 1/40:   0%|          | 0/566 [00:00<?, ?it/s]/Users/guilhermeleonardonunes/temp/masters-implementation/model/.venv/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:192: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\n",
      "Epoch 1/40: 100%|██████████| 566/566 [00:10<00:00, 55.18it/s]\n",
      "2025-12-07 22:43:09,174 - INFO - Epoch 1/40, Loss: 1.8086\n",
      "Epoch 2/40: 100%|██████████| 566/566 [00:10<00:00, 53.95it/s]\n",
      "2025-12-07 22:43:19,669 - INFO - Epoch 2/40, Loss: 1.7101\n",
      "Epoch 3/40: 100%|██████████| 566/566 [00:11<00:00, 48.10it/s]\n",
      "2025-12-07 22:43:31,440 - INFO - Epoch 3/40, Loss: 1.6869\n",
      "Epoch 4/40: 100%|██████████| 566/566 [00:10<00:00, 52.26it/s]\n",
      "2025-12-07 22:43:42,272 - INFO - Epoch 4/40, Loss: 1.6842\n",
      "Epoch 5/40: 100%|██████████| 566/566 [00:10<00:00, 55.29it/s]\n",
      "2025-12-07 22:43:52,512 - INFO - Epoch 5/40, Loss: 1.6616\n",
      "Epoch 6/40: 100%|██████████| 566/566 [00:10<00:00, 55.58it/s]\n",
      "2025-12-07 22:44:02,698 - INFO - Epoch 6/40, Loss: 1.6595\n",
      "Epoch 7/40: 100%|██████████| 566/566 [00:10<00:00, 55.95it/s]\n",
      "2025-12-07 22:44:12,817 - INFO - Epoch 7/40, Loss: 1.6435\n",
      "Epoch 8/40: 100%|██████████| 566/566 [00:10<00:00, 53.68it/s]\n",
      "2025-12-07 22:44:23,362 - INFO - Epoch 8/40, Loss: 1.6325\n",
      "Epoch 9/40: 100%|██████████| 566/566 [00:11<00:00, 51.20it/s]\n",
      "2025-12-07 22:44:34,427 - INFO - Epoch 9/40, Loss: 1.6164\n",
      "Epoch 10/40: 100%|██████████| 566/566 [00:10<00:00, 53.93it/s]\n",
      "2025-12-07 22:44:44,928 - INFO - Epoch 10/40, Loss: 1.5996\n",
      "Epoch 11/40: 100%|██████████| 566/566 [00:10<00:00, 54.79it/s]\n",
      "2025-12-07 22:44:55,264 - INFO - Epoch 11/40, Loss: 1.5643\n",
      "Epoch 12/40: 100%|██████████| 566/566 [00:10<00:00, 54.97it/s]\n",
      "2025-12-07 22:45:05,562 - INFO - Epoch 12/40, Loss: 1.5553\n",
      "Epoch 13/40: 100%|██████████| 566/566 [00:11<00:00, 50.93it/s]\n",
      "2025-12-07 22:45:16,679 - INFO - Epoch 13/40, Loss: 1.5461\n",
      "Epoch 14/40: 100%|██████████| 566/566 [00:10<00:00, 52.61it/s]\n",
      "2025-12-07 22:45:27,441 - INFO - Epoch 14/40, Loss: 1.5105\n",
      "Epoch 15/40: 100%|██████████| 566/566 [00:10<00:00, 53.11it/s]\n",
      "2025-12-07 22:45:38,103 - INFO - Epoch 15/40, Loss: 1.4862\n",
      "Epoch 16/40: 100%|██████████| 566/566 [00:10<00:00, 56.22it/s]\n",
      "2025-12-07 22:45:48,174 - INFO - Epoch 16/40, Loss: 1.4867\n",
      "Epoch 17/40: 100%|██████████| 566/566 [00:10<00:00, 56.37it/s]\n",
      "2025-12-07 22:45:58,218 - INFO - Epoch 17/40, Loss: 1.4236\n",
      "Epoch 18/40: 100%|██████████| 566/566 [00:10<00:00, 55.68it/s]\n",
      "2025-12-07 22:46:08,387 - INFO - Epoch 18/40, Loss: 1.3897\n",
      "Epoch 19/40: 100%|██████████| 566/566 [00:10<00:00, 56.05it/s]\n",
      "2025-12-07 22:46:18,488 - INFO - Epoch 19/40, Loss: 1.3746\n",
      "Epoch 20/40: 100%|██████████| 566/566 [00:11<00:00, 50.64it/s]\n",
      "2025-12-07 22:46:29,669 - INFO - Epoch 20/40, Loss: 1.3367\n",
      "Epoch 21/40: 100%|██████████| 566/566 [00:10<00:00, 51.92it/s]\n",
      "2025-12-07 22:46:40,577 - INFO - Epoch 21/40, Loss: 1.2895\n",
      "Epoch 22/40: 100%|██████████| 566/566 [00:10<00:00, 53.43it/s]\n",
      "2025-12-07 22:46:51,173 - INFO - Epoch 22/40, Loss: 1.2773\n",
      "Epoch 23/40: 100%|██████████| 566/566 [00:10<00:00, 55.37it/s]\n",
      "2025-12-07 22:47:01,398 - INFO - Epoch 23/40, Loss: 1.2435\n",
      "Epoch 24/40: 100%|██████████| 566/566 [00:10<00:00, 54.47it/s]\n",
      "2025-12-07 22:47:11,792 - INFO - Epoch 24/40, Loss: 1.2113\n",
      "Epoch 25/40: 100%|██████████| 566/566 [00:10<00:00, 53.23it/s]\n",
      "2025-12-07 22:47:22,429 - INFO - Epoch 25/40, Loss: 1.2117\n",
      "Epoch 26/40: 100%|██████████| 566/566 [00:11<00:00, 51.32it/s]\n",
      "2025-12-07 22:47:33,463 - INFO - Epoch 26/40, Loss: 1.1797\n",
      "Epoch 27/40: 100%|██████████| 566/566 [00:10<00:00, 52.25it/s]\n",
      "2025-12-07 22:47:44,299 - INFO - Epoch 27/40, Loss: 1.1556\n",
      "Epoch 28/40: 100%|██████████| 566/566 [00:10<00:00, 55.22it/s]\n",
      "2025-12-07 22:47:54,553 - INFO - Epoch 28/40, Loss: 1.1075\n",
      "Epoch 29/40: 100%|██████████| 566/566 [00:10<00:00, 56.00it/s]\n",
      "2025-12-07 22:48:04,662 - INFO - Epoch 29/40, Loss: 1.1033\n",
      "Epoch 30/40: 100%|██████████| 566/566 [00:09<00:00, 57.22it/s]\n",
      "2025-12-07 22:48:14,556 - INFO - Epoch 30/40, Loss: 1.0852\n",
      "Epoch 31/40: 100%|██████████| 566/566 [00:11<00:00, 51.27it/s]\n",
      "2025-12-07 22:48:25,597 - INFO - Epoch 31/40, Loss: 1.0744\n",
      "Epoch 32/40: 100%|██████████| 566/566 [00:10<00:00, 54.26it/s]\n",
      "2025-12-07 22:48:36,032 - INFO - Epoch 32/40, Loss: 1.0222\n",
      "Epoch 33/40: 100%|██████████| 566/566 [00:10<00:00, 54.94it/s]\n",
      "2025-12-07 22:48:46,339 - INFO - Epoch 33/40, Loss: 1.0338\n",
      "Epoch 34/40: 100%|██████████| 566/566 [00:10<00:00, 55.03it/s]\n",
      "2025-12-07 22:48:56,626 - INFO - Epoch 34/40, Loss: 1.0071\n",
      "Epoch 35/40: 100%|██████████| 566/566 [00:10<00:00, 55.61it/s]\n",
      "2025-12-07 22:49:06,807 - INFO - Epoch 35/40, Loss: 1.0120\n",
      "Epoch 36/40: 100%|██████████| 566/566 [00:10<00:00, 55.18it/s]\n",
      "2025-12-07 22:49:17,067 - INFO - Epoch 36/40, Loss: 0.9951\n",
      "Epoch 37/40: 100%|██████████| 566/566 [00:11<00:00, 48.77it/s]\n",
      "2025-12-07 22:49:28,675 - INFO - Epoch 37/40, Loss: 0.9772\n",
      "Epoch 38/40: 100%|██████████| 566/566 [00:10<00:00, 52.86it/s]\n",
      "2025-12-07 22:49:39,385 - INFO - Epoch 38/40, Loss: 0.9704\n",
      "Epoch 39/40: 100%|██████████| 566/566 [00:10<00:00, 54.84it/s]\n",
      "2025-12-07 22:49:49,708 - INFO - Epoch 39/40, Loss: 0.9658\n",
      "Epoch 40/40: 100%|██████████| 566/566 [00:10<00:00, 55.17it/s]\n",
      "2025-12-07 22:49:59,968 - INFO - Epoch 40/40, Loss: 0.9361\n"
     ]
    }
   ],
   "source": [
    "from model.training_loop import WarmupSchedulerParams\n",
    "\n",
    "\n",
    "train_history = train(\n",
    "    model=har_model,\n",
    "    video_dataset=train_dataset,\n",
    "    device='cpu',\n",
    "    # epochs=120,\n",
    "    epochs=40,\n",
    "    # epochs=90,\n",
    "    lr=1e-4,\n",
    "    weight_decay=1e-4,\n",
    "    # early_stopping=early_stopping_params,\n",
    "    warmup_scheduler_params=WarmupSchedulerParams(True, 400),\n",
    "    cross_entropy_label_smoothing=0.1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33cabcd9",
   "metadata": {},
   "source": [
    "## Training Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde2e009",
   "metadata": {},
   "source": [
    "**Early Stopping**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d6abf28",
   "metadata": {},
   "source": [
    "**Training**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd5bc8d",
   "metadata": {},
   "source": [
    "**Saving Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "66b74bb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-07 22:49:59,991 - INFO - Saving model to /Volumes/KODAK/masters/model/validation_datasets/UNSAFE-NET/model/har_model_v1.0.1_unsafe_net_20_no_obj_20251207_224959.pht...\n",
      "2025-12-07 22:50:00,195 - INFO - Model saved successfully.\n"
     ]
    }
   ],
   "source": [
    "har_model.save(\n",
    "    training_history=train_history,\n",
    "    EAR_ratio=EAR_RATIO,\n",
    "    with_object_branch=WITH_OBJECT_BRANCH,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8bf73a0",
   "metadata": {},
   "source": [
    "## Running tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe0f60c1",
   "metadata": {},
   "source": [
    "**Accuracy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a102aee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 28.80%\n"
     ]
    }
   ],
   "source": [
    "accuracy_evaluation = evaluate(har_model, test_dataset)\n",
    "print(f\"Test Accuracy: {accuracy_evaluation:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "265d4d4d",
   "metadata": {},
   "source": [
    "## Debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1f9a2abf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out.shape torch.Size([1, 8])\n",
      "out device cpu label device cpu\n",
      "logits: [[ 3.467797   -1.3171194   0.9985336  -0.15972127 -2.914488   -2.6006227\n",
      "  -1.9869895  -2.2455745 ]]\n",
      "probs: [[0.88404244 0.00738602 0.0748317  0.02349968 0.00149514 0.00204641\n",
      "  0.00377998 0.00291869]]\n",
      "entropy: 0.48787176609039307\n",
      "pred: 0 label: 0\n"
     ]
    }
   ],
   "source": [
    "import torch, torch.nn.functional as F\n",
    "device = 'cpu'   # match training device\n",
    "har_model.to(device)\n",
    "har_model.eval()\n",
    "\n",
    "sample = train_dataset[0]\n",
    "graphs_objects = [g.to(device) for g in sample.graphs_objects]\n",
    "graphs_joints = [g.to(device) for g in sample.graphs_joints]\n",
    "label = sample.label.unsqueeze(0).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    out = har_model(graphs_objects, graphs_joints)   # expect [1, num_classes]\n",
    "    probs = F.softmax(out, dim=-1)\n",
    "    ent = -(probs * probs.log()).sum(dim=-1)     # entropy\n",
    "    pred = torch.argmax(probs, dim=-1)\n",
    "\n",
    "print(\"out.shape\", out.shape)\n",
    "print(\"out device\", out.device, \"label device\", label.device)\n",
    "print(\"logits:\", out.cpu().numpy())\n",
    "print(\"probs:\", probs.cpu().numpy())\n",
    "print(\"entropy:\", ent.item())\n",
    "print(\"pred:\", pred.item(), \"label:\", label.item())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a7199e",
   "metadata": {},
   "source": [
    "**Mapping Consistency - Distribution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9da92364",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TRAIN ===\n",
      "len: 566\n",
      "unique labels: [0, 1, 2, 3, 4, 5, 6, 7]\n",
      "counts: Counter({0: 178, 2: 129, 1: 97, 4: 50, 3: 48, 5: 23, 7: 22, 6: 19})\n",
      "labels_map (sample): {'0_safe_walkway_violation': 0, '1_unauthorized_intervention': 1, '2_opened_panel cover': 2, '3_carrying_overload_with_forklift': 3, '4_safe_walkway': 4, '5_authorized_intervention': 5, '6_closed_panel_cover': 6, '7_safe_carrying': 7}\n",
      "\n",
      "=== TEST ===\n",
      "len: 125\n",
      "unique labels: [0, 1, 2, 3, 4, 5, 6, 7]\n",
      "counts: Counter({0: 32, 4: 25, 5: 15, 2: 13, 6: 13, 1: 11, 3: 8, 7: 8})\n",
      "labels_map (sample): {'0_safe_walkway_violation': 0, '1_unauthorized_intervention': 1, '2_opened_panel cover': 2, '3_carrying_overload_with_forklift': 3, '4_safe_walkway': 4, '5_authorized_intervention': 5, '6_closed_panel_cover': 6, '7_safe_carrying': 7}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "def inspect_dataset(dataset, name):\n",
    "    labels = [int(s.label) for s in dataset]\n",
    "    print(f\"=== {name} ===\")\n",
    "    print(\"len:\", len(labels))\n",
    "    print(\"unique labels:\", sorted(set(labels)))\n",
    "    print(\"counts:\", Counter(labels))\n",
    "    print(\"labels_map (sample):\", getattr(dataset, \"labels_map\", None))\n",
    "    print()\n",
    "\n",
    "inspect_dataset(train_dataset, \"TRAIN\")\n",
    "inspect_dataset(test_dataset, \"TEST\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a023a48",
   "metadata": {},
   "source": [
    "**Prediction Distribution - Predicts only few classes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ac297c99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred distribution: Counter({2: 34, 0: 30, 1: 21, 4: 19, 3: 14, 5: 5, 7: 1, 6: 1})\n",
      "true distribution : Counter({0: 32, 4: 25, 5: 15, 2: 13, 6: 13, 1: 11, 3: 8, 7: 8})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import torch, torch.nn.functional as F\n",
    "\n",
    "def pred_distribution(model, dataset, device='cpu'):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    truths = []\n",
    "    with torch.no_grad():\n",
    "        for s in dataset:\n",
    "            graphs_objects = [g.to(device) for g in s.graphs_objects]\n",
    "            graphs_joints  = [g.to(device) for g in s.graphs_joints]\n",
    "            out = model(graphs_objects, graphs_joints)  # [1, C]\n",
    "            preds.append(int(torch.argmax(out, dim=-1)))\n",
    "            truths.append(int(s.label))\n",
    "    print(\"pred distribution:\", Counter(preds))\n",
    "    print(\"true distribution :\", Counter(truths))\n",
    "    return preds, truths\n",
    "\n",
    "preds, truths = pred_distribution(har_model, test_dataset, device='cpu')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebdd34ac",
   "metadata": {},
   "source": [
    "**Confusion Matrix - Per Class Prediction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "edb7bd7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      " [[11 11  0  1  8  1  0  0]\n",
      " [ 4  5  0  0  1  1  0  0]\n",
      " [ 2  0  8  2  1  0  0  0]\n",
      " [ 3  0  1  4  0  0  0  0]\n",
      " [ 6  3  7  2  5  1  0  1]\n",
      " [ 1  2  7  0  3  2  0  0]\n",
      " [ 1  0  8  2  1  0  1  0]\n",
      " [ 2  0  3  3  0  0  0  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.3667    0.3438    0.3548        32\n",
      "           1     0.2381    0.4545    0.3125        11\n",
      "           2     0.2353    0.6154    0.3404        13\n",
      "           3     0.2857    0.5000    0.3636         8\n",
      "           4     0.2632    0.2000    0.2273        25\n",
      "           5     0.4000    0.1333    0.2000        15\n",
      "           6     1.0000    0.0769    0.1429        13\n",
      "           7     0.0000    0.0000    0.0000         8\n",
      "\n",
      "    accuracy                         0.2880       125\n",
      "   macro avg     0.3486    0.2905    0.2427       125\n",
      "weighted avg     0.3622    0.2880    0.2613       125\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "cm = confusion_matrix(truths, preds)\n",
    "print(\"Confusion matrix:\\n\", cm)\n",
    "print(classification_report(truths, preds, digits=4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5086bf7f",
   "metadata": {},
   "source": [
    "**Confusion Matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4c388b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "def plot_confusion_matrix(cm, class_names, normalize=True, figsize=(10, 8), cmap=\"Blues\"):\n",
    "    \"\"\"\n",
    "    Visual, attractive confusion matrix with optional normalization.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype(\"float\") / cm.sum(axis=1, keepdims=True)\n",
    "        cm = np.nan_to_num(cm)  # handle div-by-zero\n",
    "\n",
    "    plt.figure(figsize=figsize)\n",
    "    sns.set(font_scale=1.2)\n",
    "    sns.heatmap(\n",
    "        cm,\n",
    "        annot=True,\n",
    "        fmt=\".2f\" if normalize else \"d\",\n",
    "        cmap=cmap,\n",
    "        square=True,\n",
    "        cbar=True,\n",
    "        linewidths=0.5,\n",
    "        linecolor=\"gray\",\n",
    "        annot_kws={\"size\": 12, \"weight\": \"bold\"}\n",
    "    )\n",
    "\n",
    "    plt.title(\"Matriz de Confusão\", fontsize=18, weight=\"bold\")\n",
    "    plt.ylabel(\"Rótulo Verdadeiro\", fontsize=14)\n",
    "    plt.xlabel(\"Rótulo Previsto\", fontsize=14)\n",
    "\n",
    "    plt.xticks(np.arange(len(class_names)) + 0.5, class_names, rotation=45, ha=\"right\")\n",
    "    plt.yticks(np.arange(len(class_names)) + 0.5, class_names, rotation=0)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da8d9f24",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mstr\u001b[39m(Path(os\u001b[38;5;241m.\u001b[39mgetcwd())\u001b[38;5;241m.\u001b[39mparent))\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mvalidation\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mactions_map\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m UNSAFE_NET_ORDERED\n\u001b[0;32m----> 7\u001b[0m plot_confusion_matrix(\u001b[43mcm\u001b[49m, UNSAFE_NET_ORDERED, normalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cm' is not defined"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(str(Path(os.getcwd()).parent))\n",
    "from validation.actions_map import UNSAFE_NET_ORDERED\n",
    "\n",
    "plot_confusion_matrix(cm, UNSAFE_NET_ORDERED, normalize=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "888925f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ordered Action Classes:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "NameError",
     "evalue": "name 'UNSAFE_NET_ORDERED' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m display(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOrdered Action Classes:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mUNSAFE_NET_ORDERED\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'UNSAFE_NET_ORDERED' is not defined"
     ]
    }
   ],
   "source": [
    "display(\"Ordered Action Classes:\")\n",
    "print(UNSAFE_NET_ORDERED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "085e5fc5",
   "metadata": {},
   "source": [
    "# ## LateX Table\n",
    "\n",
    "```latex\n",
    "\\begin{table}[h!]\n",
    "\\centering\n",
    "\\caption{Classes de ações do dataset Unsafe Net}\n",
    "\\label{tab:unsafenet_classes}\n",
    "\\begin{tabular}{c l}\n",
    "\\hline\n",
    "\\textbf{ID} & \\textbf{Ação} \\\\\n",
    "\\hline\n",
    "0 & Safe Walkway Violation \\\\\n",
    "1 & Unauthorized Intervention \\\\\n",
    "2 & Opened Panel Cover \\\\\n",
    "3 & Carrying Overload Forklift \\\\\n",
    "4 & Safe Walkway \\\\\n",
    "5 & Authorized Intervention \\\\\n",
    "6 & Closed Panel Cover \\\\\n",
    "7 & Safe Carrying \\\\\n",
    "\\hline\n",
    "\\end{tabular}\n",
    "\\end{table}\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
