{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "278e58c8",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e23c27e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading config...\n",
      "Loading secrets...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-13 15:31:36,278 - INFO - Sentry DSN set to: https://f4f21cc936b3ba9f5dbc1464b7a40ea4@o4504168838070272.ingest.us.sentry.io/4506464560414720\n",
      "2025-11-13 15:31:36,281 - INFO - Sentry initialized with environment: development\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import sys\n",
    "sys.path.append(str(Path(os.getcwd()).parent))\n",
    "\n",
    "from settings.global_settings import GlobalSettings\n",
    "\n",
    "config = GlobalSettings.get_config(\n",
    "    config_file = \"../config.ini\",\n",
    "    secrets_file = \"../secrets.ini\"\n",
    ")\n",
    "from dataset.video_loader import VideoDataLoader\n",
    "from dataset.video_dataset import VideoDataset\n",
    "from model.multimodal_har_model import MultiModalHARModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc045b93",
   "metadata": {},
   "source": [
    "**Parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4724a83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PHT_PATH = \"/Volumes/KODAK/masters/model/validation_datasets/NW-UCLA/model/har_model_v1.0.0_nw_ucla_2025-11-11 09:45:21.993320.pht\"\n",
    "VALIDATION_DIR = os.path.join(\n",
    "    config.model_settings.video_data_dir,\n",
    "    \"validation\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b908ef45",
   "metadata": {},
   "source": [
    "## Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86bbbc15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-13 15:31:38,366 - INFO - [VideoDataLoader] Loding action videos for action: a01\n",
      "2025-11-13 15:31:38,405 - INFO - [VideoDataLoader] Loding action videos for action: a02\n",
      "2025-11-13 15:31:38,505 - INFO - [VideoDataLoader] Loding action videos for action: a03\n",
      "2025-11-13 15:31:38,566 - INFO - [VideoDataLoader] Loding action videos for action: a04\n",
      "2025-11-13 15:31:38,607 - INFO - [VideoDataLoader] Loding action videos for action: a05\n",
      "2025-11-13 15:31:38,642 - INFO - [VideoDataLoader] Loding action videos for action: a06\n",
      "2025-11-13 15:31:38,673 - INFO - [VideoDataLoader] Loding action videos for action: a08\n",
      "2025-11-13 15:31:38,824 - INFO - [VideoDataLoader] Loding action videos for action: a09\n",
      "2025-11-13 15:31:38,887 - INFO - [VideoDataLoader] Loding action videos for action: a11\n",
      "2025-11-13 15:31:38,930 - INFO - [VideoDataLoader] Loding action videos for action: a12\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "validation_video_data_loader = VideoDataLoader(\n",
    "    path=VALIDATION_DIR,\n",
    ")\n",
    "validation_dataset = VideoDataset(\n",
    "    video_data_loader=validation_video_data_loader,\n",
    "    normalization_type=\"across_frames\",\n",
    ")\n",
    "\n",
    "len(validation_dataset)\n",
    "for _ in validation_dataset:\n",
    "    pass\n",
    "\n",
    "\n",
    "display(len(validation_dataset.labels_map))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e8f41e",
   "metadata": {},
   "source": [
    "## Loading Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b09102f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-13 15:31:39,452 - INFO - Loading model from /Volumes/KODAK/masters/model/validation_datasets/NW-UCLA/model/har_model_v1.0.0_nw_ucla_2025-11-11 09:45:21.993320.pht...\n",
      "2025-11-13 15:31:39,530 - INFO - Model config: {'obj_in': 5, 'joint_in': 3, 'gat_hidden': 128, 'gat_out': 128, 'temporal_hidden': 128, 'num_classes': 10, 'dropout': 0.1}\n",
      "2025-11-13 15:31:39,531 - INFO - Model configuration: {'obj_in': 5, 'joint_in': 3, 'gat_hidden': 128, 'gat_out': 128, 'temporal_hidden': 128, 'num_classes': 10, 'dropout': 0.1}\n",
      "2025-11-13 15:31:39,593 - INFO - ✅ Model loaded and ready for inference\n"
     ]
    }
   ],
   "source": [
    "har_model, _ = MultiModalHARModel.load(\n",
    "    checkpoint_path=MODEL_PHT_PATH\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0eb2ff",
   "metadata": {},
   "source": [
    "## Quantitative Validation\n",
    "\n",
    "- Accuracy\n",
    "- AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d91a1f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "import torch\n",
    "from torch import nn\n",
    "from typing import Tuple, List\n",
    "from tqdm import tqdm\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate_model(\n",
    "    model: nn.Module,\n",
    "    dataset: VideoDataset,\n",
    "    device: torch.device\n",
    ") -> Tuple[float, float]:\n",
    "    \"\"\"\n",
    "    Evaluates a trained model on a VideoDataset.\n",
    "    Computes accuracy and macro-averaged AUC.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    y_true_list: List[int] = []\n",
    "    y_pred_logits_list: List[torch.Tensor] = []\n",
    "\n",
    "    for video_data in tqdm(dataset, desc=\"Evaluating\"):\n",
    "        graphs_objects = [g.to(device) for g in video_data.graphs_objects]\n",
    "        graphs_joints = [g.to(device) for g in video_data.graphs_joints]\n",
    "        label = video_data.label.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        logits: torch.Tensor = model(graphs_objects, graphs_joints)\n",
    "        y_pred_logits_list.append(logits.cpu())\n",
    "        y_true_list.append(label.cpu().item())\n",
    "\n",
    "    # Concatenate results\n",
    "    y_true = torch.tensor(y_true_list)\n",
    "    y_pred_logits = torch.cat(y_pred_logits_list, dim=0)\n",
    "\n",
    "    # Compute metrics\n",
    "    accuracy, auc = compute_metrics(y_true, y_pred_logits)\n",
    "    return accuracy, auc\n",
    "\n",
    "\n",
    "def compute_metrics(\n",
    "    y_true: torch.Tensor,\n",
    "    y_pred_logits: torch.Tensor\n",
    ") -> Tuple[float, float]:\n",
    "    \"\"\"\n",
    "    Compute accuracy and macro-AUC.\n",
    "    Args:\n",
    "        y_true: Tensor of shape (N,) with integer labels.\n",
    "        y_pred_logits: Tensor of shape (N, C) with raw model outputs (before softmax).\n",
    "    Returns:\n",
    "        (accuracy, macro_auc)\n",
    "    \"\"\"\n",
    "    y_true_np = y_true.numpy()\n",
    "    y_pred_np = torch.softmax(y_pred_logits, dim=1).numpy()\n",
    "\n",
    "    preds = y_pred_np.argmax(axis=1)\n",
    "    accuracy: float = (preds == y_true_np).mean()\n",
    "\n",
    "    try:\n",
    "        auc: float = roc_auc_score(y_true_np, y_pred_np, multi_class='ovr', average='macro')\n",
    "    except ValueError:\n",
    "        auc = float('nan')\n",
    "\n",
    "    return accuracy, auc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "864e99b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 152/152 [00:02<00:00, 54.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.7368, AUC: 0.9731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "har_model.to(device)\n",
    "\n",
    "accuracy, auc = evaluate_model(har_model, validation_dataset, device)\n",
    "print(f\"Validation Accuracy: {accuracy:.4f}, AUC: {auc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2689dd8",
   "metadata": {},
   "source": [
    "## Qualitative Validation\n",
    "\n",
    "- Graphic Analysis - Plotting with t-SNE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
